{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmghaly/arabicthon/blob/main/arabicthon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkEbYOfqybzS"
      },
      "source": [
        "#بداية الملف"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXqKsjqdSt1"
      },
      "source": [
        "Connect Google Colab with Google drive with this code\n",
        "ربط جوجل كولاب بجوجل درايف من خلال هذا الكود\n",
        "\n",
        "*   يجب القيام بهذا كل مرة نستخدم فيها النوت بوك\n",
        "*    يرجى ملاحظة أن تشغيل هذا الكود أدناه سينشئ فولدر جديد في الجوجل درايف الخاص بكم\n",
        "*   اسم الفولدر: arabicthon\n",
        "*   وكل البيانات التي ستتم معالجتها وتحميلها ستكون موجودة في هذا الفولدر\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Tb5B_c0qvp",
        "outputId": "3706d0bb-b4e6-43b2-c69c-21133dd9d77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "cwd=\"/content/drive/MyDrive/arabicthon\" #you can change the folder name from \"arcompling\" to the folder you have the notebook in\n",
        "if not os.path.exists(cwd): os.makedirs(cwd)  #if the directory doesn't exist, create it\n",
        "os.chdir(cwd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zzTg6GMqh3H"
      },
      "source": [
        "#تنظيم النوتبوك"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyHmkfi6qlkd"
      },
      "source": [
        "هذا النوتبوك يبين تسلسل العمل على مشروع أطر الأفعال العربية وبالتالي فهو يبين كيفية البدء من تجميع مصادر البيانات، وتجهيزها واستخلاص النماذج منها، وتدريب نظام الذكاء الاصطناعي عليها، ثم إنشاء نموذج الذكاء الاصناعي المستخدم في تقديم النواتج النهائية للمشروع. عند الرغبة في رؤية عمل النموذج فورا، يرجى الذهاب إلى نهاية الملف عند القسم الثالث المعنون: تطبيق النموذج واستخدامه ونتائجه"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUKOu4BWrrRc"
      },
      "source": [
        "#القسم الأول - تحميل البيانات وتجهيزها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDHOIUO0rxr8"
      },
      "source": [
        "يتم هنا تحميل النصوص المستخدمة في تدريب وتغذية نظام الذكاء الاصطناعي. وحتى الآن النصوص المستخدمة هي: نص القرآن الكريم ونوص مجمعة من مواقع إخبارية باللغة العربية، ويمكن إضافة المزيد من البيانات مع الاستمرار في المشروع."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLlDAzl4Y-9k"
      },
      "source": [
        "يجب القيام بهذا الجزء مرة واحدة عند البدء في المشروع\n",
        "\n",
        "\n",
        "*   تنزيل الملف المضغوط من الموقع\n",
        "*   فك الملف المضغوط\n",
        "*  إعادة تسمية الفولدر الذي جرى فيه فك الملف المضغوط إلى quran-text\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUgO3H82sL60"
      },
      "source": [
        "## أولا - تحميل وتجهيز النص القرآني"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Jy79mcsRTX"
      },
      "source": [
        "الخطوة الأولى هي العثور على صيغة نصية للقرآن الكريم وتحميلها على الفولدر الذي نعمل داخله. وفي هذه الحالة نقوم بتحميل الملف بشكل مضغوط، وفكه في مكان محدد وتغيير اسم الفولدر الذي يتم فكه فيه."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNriMjo4dd-g"
      },
      "source": [
        "تحميل الملف المضغوط للقرآن من هنا ووضعه على نفس الفولدر الذي يوجد به النوتبوك:\n",
        "http://quran.mursil.com/Web-Print-Publishing-Quran-Text-Graphics-Fonts-and-Downloads/txt-format-unicode-text\n",
        "\n",
        "بعد تحميل الملف المضغوط الذي يتضمن الملفات النصية للقرآن، نستخدم أمر لينوكس على جوجل كولاب لفك الملف المضغوط.\n",
        "لا نحتاج للقيام بذلك سوى مرة واحدة"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BBZJuKpVaNw",
        "outputId": "e6dc95f5-760e-46fb-ca72-649ad3ecb01c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-26 13:30:48--  http://quran.mursil.com/Web-Print-Publishing-Quran-Text-Graphics-Fonts-and-Downloads/txt-format-unicode-text/Tanzil.info-13-txt-files.zip?attredirects=0\n",
            "Resolving quran.mursil.com (quran.mursil.com)... 172.217.2.115, 2607:f8b0:4004:814::2013\n",
            "Connecting to quran.mursil.com (quran.mursil.com)|172.217.2.115|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: http://c9d26594-a-404942ba-s-sites.googlegroups.com/a/mursil.com/thequranpublishingresources/Web-Print-Publishing-Quran-Text-Graphics-Fonts-and-Downloads/txt-format-unicode-text/Tanzil.info-13-txt-files.zip?attachauth=ANoY7cr7rWpWQD20xhYywPL1hG6_Byada_qOeT4O5wk2g7ljekD6AY4u_KHBXAYHQGc2KBg5uo3f6rhle-nBEznemzwxl2diVspxIQVmri1Y5LCaFmoSyLJkm_20Sq7mJw_gyen2pdoF0JK03V7t6z1Gr69_JTt8-eqjq10YMVLfZ1V5CCxkN2_06GNEjN66wUCJfLK9t8uxApNQeX7JUNpnUUrLEfu2Mlk6RaKqhI3TrFYs_gGkrK_obHpV5-7f0tlrzVWCjd_q_jx_v8ANxW9blTwy6_tbu9c7TtBpCBhtdMGXpjKMc9UZOkADMoWb0Ql4otBD5LXRyYi3MHnFNY1NobvWuQwbmIx73GOERB6Zswq0F5fXMu0%3D&attredirects=0 [following]\n",
            "--2022-05-26 13:30:48--  http://c9d26594-a-404942ba-s-sites.googlegroups.com/a/mursil.com/thequranpublishingresources/Web-Print-Publishing-Quran-Text-Graphics-Fonts-and-Downloads/txt-format-unicode-text/Tanzil.info-13-txt-files.zip?attachauth=ANoY7cr7rWpWQD20xhYywPL1hG6_Byada_qOeT4O5wk2g7ljekD6AY4u_KHBXAYHQGc2KBg5uo3f6rhle-nBEznemzwxl2diVspxIQVmri1Y5LCaFmoSyLJkm_20Sq7mJw_gyen2pdoF0JK03V7t6z1Gr69_JTt8-eqjq10YMVLfZ1V5CCxkN2_06GNEjN66wUCJfLK9t8uxApNQeX7JUNpnUUrLEfu2Mlk6RaKqhI3TrFYs_gGkrK_obHpV5-7f0tlrzVWCjd_q_jx_v8ANxW9blTwy6_tbu9c7TtBpCBhtdMGXpjKMc9UZOkADMoWb0Ql4otBD5LXRyYi3MHnFNY1NobvWuQwbmIx73GOERB6Zswq0F5fXMu0%3D&attredirects=0\n",
            "Resolving c9d26594-a-404942ba-s-sites.googlegroups.com (c9d26594-a-404942ba-s-sites.googlegroups.com)... 172.253.62.137, 2607:f8b0:4004:c07::89\n",
            "Connecting to c9d26594-a-404942ba-s-sites.googlegroups.com (c9d26594-a-404942ba-s-sites.googlegroups.com)|172.253.62.137|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://c9d26594-a-404942ba-s-sites.googlegroups.com/a/mursil.com/thequranpublishingresources/Web-Print-Publishing-Quran-Text-Graphics-Fonts-and-Downloads/txt-format-unicode-text/Tanzil.info-13-txt-files.zip?attachauth=ANoY7cr7rWpWQD20xhYywPL1hG6_Byada_qOeT4O5wk2g7ljekD6AY4u_KHBXAYHQGc2KBg5uo3f6rhle-nBEznemzwxl2diVspxIQVmri1Y5LCaFmoSyLJkm_20Sq7mJw_gyen2pdoF0JK03V7t6z1Gr69_JTt8-eqjq10YMVLfZ1V5CCxkN2_06GNEjN66wUCJfLK9t8uxApNQeX7JUNpnUUrLEfu2Mlk6RaKqhI3TrFYs_gGkrK_obHpV5-7f0tlrzVWCjd_q_jx_v8ANxW9blTwy6_tbu9c7TtBpCBhtdMGXpjKMc9UZOkADMoWb0Ql4otBD5LXRyYi3MHnFNY1NobvWuQwbmIx73GOERB6Zswq0F5fXMu0%3D&attredirects=0 [following]\n",
            "--2022-05-26 13:30:48--  https://c9d26594-a-404942ba-s-sites.googlegroups.com/a/mursil.com/thequranpublishingresources/Web-Print-Publishing-Quran-Text-Graphics-Fonts-and-Downloads/txt-format-unicode-text/Tanzil.info-13-txt-files.zip?attachauth=ANoY7cr7rWpWQD20xhYywPL1hG6_Byada_qOeT4O5wk2g7ljekD6AY4u_KHBXAYHQGc2KBg5uo3f6rhle-nBEznemzwxl2diVspxIQVmri1Y5LCaFmoSyLJkm_20Sq7mJw_gyen2pdoF0JK03V7t6z1Gr69_JTt8-eqjq10YMVLfZ1V5CCxkN2_06GNEjN66wUCJfLK9t8uxApNQeX7JUNpnUUrLEfu2Mlk6RaKqhI3TrFYs_gGkrK_obHpV5-7f0tlrzVWCjd_q_jx_v8ANxW9blTwy6_tbu9c7TtBpCBhtdMGXpjKMc9UZOkADMoWb0Ql4otBD5LXRyYi3MHnFNY1NobvWuQwbmIx73GOERB6Zswq0F5fXMu0%3D&attredirects=0\n",
            "Connecting to c9d26594-a-404942ba-s-sites.googlegroups.com (c9d26594-a-404942ba-s-sites.googlegroups.com)|172.253.62.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3321758 (3.2M) [application/octet-stream]\n",
            "Saving to: ‘quran-text.zip’\n",
            "\n",
            "quran-text.zip      100%[===================>]   3.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-05-26 13:30:49 (31.4 MB/s) - ‘quran-text.zip’ saved [3321758/3321758]\n",
            "\n",
            "Archive:  quran-text.zip\n",
            "   creating: Tanzil.info-13-txt-files/\n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple-clean-With-Ayah-Numbers.txt.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple-clean.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple-enhanced-With-Ayah-Numbers.txt.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple-enhanced.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple-min-With-Ayah-Numbers.txt.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple-min.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple-With-Ayah-Numbers.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-simple.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-uthmani-A.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-uthmani-B.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-uthmani-min-With-Ayah-Numbers.txt.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-uthmani-min.txt  \n",
            "  inflating: Tanzil.info-13-txt-files/_quran-uthmani-With-Ayah-Numbers.txt.txt  \n",
            "successfully saved the Quran text files into the directory quran-text\n"
          ]
        }
      ],
      "source": [
        "!wget -O quran-text.zip http://quran.mursil.com/Web-Print-Publishing-Quran-Text-Graphics-Fonts-and-Downloads/txt-format-unicode-text/Tanzil.info-13-txt-files.zip?attredirects=0&d=1 \n",
        "!unzip quran-text.zip\n",
        "!mv Tanzil.info-13-txt-files quran-text\n",
        "print(\"successfully saved the Quran text files into the directory quran-text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmXn5MUge85P"
      },
      "source": [
        "وبعد ذلك نقرأ ملفا معينا يتضمن أرقام السور والآيات، ونستخدم هذه المعلومات في إعداد قائمة بالآيات، وبالآيات مقسمة إلى كلمات."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adz0BVmczUw5",
        "outputId": "42a12dc8-8e20-4f96-ef9a-dffe8372fd81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quran-text/_quran-simple-clean-With-Ayah-Numbers.txt.txt\n",
            "عدد آيات القرآن 6236\n",
            "عدد كلمات القرآن: 78245\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#تحديد مسار الملف\n",
        "file_name=\"_quran-simple-clean-With-Ayah-Numbers.txt.txt\"\n",
        "folder_name=\"quran-text\"\n",
        "fpath=os.path.join(folder_name,file_name)\n",
        "print(fpath)\n",
        "#قراءة الملف\n",
        "fopen=open(fpath)\n",
        "lines=fopen.readlines()\n",
        "fopen.close()\n",
        "#معالجة الملف بحيث نأخذ السطور التي بها آيات فقط، وتقسيم كل سطر إلى رقم السورة ورقم الآية ونص الآية\n",
        "new_lines=[]\n",
        "for li in lines:\n",
        "  li=li.strip(\"\\n\")\n",
        "  li_split=li.split(\"|\")\n",
        "  if len(li_split)!=3: continue\n",
        "  new_lines.append(li_split)\n",
        "print(\"عدد آيات القرآن\", len(new_lines))\n",
        "\n",
        "final_list=[]\n",
        "aya_words_list=[]\n",
        "all_quran_words=[]\n",
        "for item in new_lines:\n",
        "  aya_text=item[2]\n",
        "  aya_sura_num=\"%s-%s\"%(item[0],item[1])\n",
        "  words=aya_text.split()\n",
        "  aya_words_list.append(words)\n",
        "  for w0 in words:\n",
        "    final_list.append((aya_sura_num,w0))\n",
        "  all_quran_words.extend(words)\n",
        "\n",
        "out_fopen=open(\"quran-annotation-simple.tsv\",\"w\")\n",
        "for a,b in final_list:\n",
        "  line=\"%s\\t%s\\n\"%(a,b)\n",
        "  out_fopen.write(line)\n",
        "out_fopen.close()\n",
        "print(\"عدد كلمات القرآن:\", len(final_list))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWwpNTv3t6FK"
      },
      "source": [
        "\n",
        "\n",
        "*   بعد تنفيذ الخطوة السابقة، سيكون لدينا ملف جديد\n",
        "*   quran-annotation-simple.tsv\n",
        "*   وهذا الملف هو الذي سنستخدمه في إنشاء ملف التبويب على جوجل شيت\n",
        "*   https://docs.google.com/spreadsheets/d/1sxicpcgGjTPj1V3jFsytc0XPh0tOB3mbj3y8EvNo8tg/edit?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgaDxRuTwdu2"
      },
      "source": [
        "سنقوم أيضا بحفظ قائمة الآيات المقسمة إلى كلمات في ملف نصي منفصل كي نستخدمها في إنشاء نموذج متجه الكلمات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkyxFj7ywubX",
        "outputId": "c8bd6db6-68c3-4453-db90-c72a3529861b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved text file successfully: tokenized-text/quran.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "text_dir=\"tokenized-text\"\n",
        "if not os.path.exists(text_dir): os.makedirs(text_dir)\n",
        "cur_fname=\"quran.txt\"\n",
        "cur_fpath=os.path.join(text_dir,cur_fname)\n",
        "cur_fopen=open(cur_fpath,\"w\")\n",
        "for aya0 in aya_words_list:\n",
        "  aya_line=\" \".join(aya0)\n",
        "  cur_fopen.write(aya_line+\"\\n\")\n",
        "cur_fopen.close()\n",
        "print(\"saved text file successfully:\", cur_fpath)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMEkYxu51zMK"
      },
      "source": [
        "##ثانيا - تحميل وتجهيز النص الإخباري\n",
        "هذه البيانات مأخوذة من مشروع \n",
        "*  ANT Corpus - Arabic News Texts Corpus https://antcorpus.github.io/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLlHwREa2nV3"
      },
      "source": [
        "أول خطوة هي تحميل الملف المضغوط من الموقع، ثم فكه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jsIWq9tGJVh"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/antcorpus/antcorpus.multisource.data/archive/refs/tags/v2.1.zip\n",
        "!unzip v2.1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT40OlIa20oB"
      },
      "source": [
        "سنستخدم مكتبة نظام التشغيل في بايثون للدخول على كل الفولدرات الفرعية تحت الفولدر الذي تم فيه فك الملف المضغوط، وتحديد المصادر والفئات التي يتم تنظيم البيانات من خلالها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iujEqhduk5sI",
        "outputId": "b2ec4634-f160-4dbf-f3e0-063909199569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "العدد الكلي للملفات 31525\n",
            "هذه هي تقسيمات البيانات الإخبارية\n",
            "Alarabia/culture\n",
            "Alarabia/economy\n",
            "Alarabia/internationalNews\n",
            "Alarabia/sport\n",
            "Alarabia/technology\n",
            "BBC/culture\n",
            "BBC/economy\n",
            "BBC/internationalNews\n",
            "BBC/middleEast\n",
            "BBC/sport\n",
            "BBC/technology\n",
            "CNN/economy\n",
            "CNN/internationalNews\n",
            "CNN/middleEast\n",
            "CNN/sport\n",
            "CNN/technology\n",
            "France24/culture\n",
            "France24/economy\n",
            "France24/internationalNews\n",
            "France24/middleEast\n",
            "France24/sport\n",
            "SkyNews/economy\n",
            "SkyNews/internationalNews\n",
            "SkyNews/middleEast\n",
            "SkyNews/sport\n",
            "SkyNews/technology\n",
            "عدد التقسيمات - من المصدر ونوع الأخبار 26\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from itertools import groupby\n",
        "ant_file_list=[]\n",
        "root_dir=\"antcorpus.multisource.data-2.1\"\n",
        "for root0,dirs0,files0 in os.walk(root_dir):\n",
        "  for fname0 in files0:\n",
        "    key=root0[len(root_dir):].strip(\"/\")\n",
        "    cur_fpath=os.path.join(root0,fname0)\n",
        "    if not cur_fpath.endswith(\".txt\"): continue\n",
        "    ant_file_list.append((key,cur_fpath))\n",
        "\n",
        "print(\"العدد الكلي للملفات\", len(ant_file_list))\n",
        "\n",
        "print(\"هذه هي تقسيمات البيانات الإخبارية\")\n",
        "grouped_files=[(key,[v[1] for v in list(group)]) for key,group in groupby(ant_file_list,lambda x:x[0])]\n",
        "\n",
        "for k0,grp0 in grouped_files:\n",
        "  print(k0)\n",
        "print(\"عدد التقسيمات - من المصدر ونوع الأخبار\", len(grouped_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7YTNR9c3nx_"
      },
      "source": [
        "إنشاء بعض الأكواد المساعدة في تجهيز وتنظيف النص، وتقسيمه إلى كلمات. هذه الأكواد ستوضع في ملف بايثون خاص بها موجود على جيت هاب"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHQVvSwRlCUA",
        "outputId": "49901100-b5b8-4c70-d37a-dc28c85344f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "خصصت السلطات المصرية خطوطا هاتفية لتلقي بلاغات بشأن أي أخبار \"كاذبة وشائعات\" تلحق الضرر بالمواطنين أو بأمن البلاد في وسائل الإعلام ووسائل التواصل الاجتماعي، وفق ما أعلنت النيابة العامة المصرية الاثنين.\n",
            "['خصصت', 'السلطات', 'المصرية', 'خطوطا', 'هاتفية', 'لتلقي', 'بلاغات', 'بشأن', 'أي', 'أخبار', '\"', 'كاذبة', 'وشائعات', '\"', 'تلحق', 'الضرر', 'بالمواطنين', 'أو', 'بأمن', 'البلاد', 'في', 'وسائل', 'الإعلام', 'ووسائل', 'التواصل', 'الاجتماعي', '،', 'وفق', 'ما', 'أعلنت', 'النيابة', 'العامة', 'المصرية', 'الاثنين', '.']\n",
            "ويأتي هذا الإعلان قبل نحو أسبوعين من الانتخابات الرئاسية المقررة من 26 إلى 28 آذار/مارس الحالي.\n",
            "['ويأتي', 'هذا', 'الإعلان', 'قبل', 'نحو', 'أسبوعين', 'من', 'الانتخابات', 'الرئاسية', 'المقررة', 'من', '26', 'إلى', '28', 'آذار', '/', 'مارس', 'الحالي', '.']\n",
            "في إطار ضبط وسائل الإعلام المصرية المختلفة إضافة إلى وسائل التواصل الاجتماعي، وقبل بدء الانتخابات الرئاسية المقررة نهاية الشهر الجاري، أعلنت النيابة العامة مساء الاثنين أنها خصصت خطوطا هاتفية لتلقي بلاغات على خدمة الواتساب أو الرسائل القصيرة بشأن أي أخبار \"كاذبة وشائعات\" تلحق الضرر بالمواطنين أو بأمن البلاد.\n",
            "['في', 'إطار', 'ضبط', 'وسائل', 'الإعلام', 'المصرية', 'المختلفة', 'إضافة', 'إلى', 'وسائل', 'التواصل', 'الاجتماعي', '،', 'وقبل', 'بدء', 'الانتخابات', 'الرئاسية', 'المقررة', 'نهاية', 'الشهر', 'الجاري', '،', 'أعلنت', 'النيابة', 'العامة', 'مساء', 'الاثنين', 'أنها', 'خصصت', 'خطوطا', 'هاتفية', 'لتلقي', 'بلاغات', 'على', 'خدمة', 'الواتساب', 'أو', 'الرسائل', 'القصيرة', 'بشأن', 'أي', 'أخبار', '\"', 'كاذبة', 'وشائعات', '\"', 'تلحق', 'الضرر', 'بالمواطنين', 'أو', 'بأمن', 'البلاد', '.']\n",
            "وتضمن البيان الصادر عن النيابة العامة أنها \"خصصت أرقام هواتف محمولة لتلقي البلاغات على خدمتي واتساب والرسائل النصية القصيرة على أن يشمل البلاغ اسم المبلغ وبياناته الشخصية\".\n",
            "['وتضمن', 'البيان', 'الصادر', 'عن', 'النيابة', 'العامة', 'أنها', '\"', 'خصصت', 'أرقام', 'هواتف', 'محمولة', 'لتلقي', 'البلاغات', 'على', 'خدمتي', 'واتساب', 'والرسائل', 'النصية', 'القصيرة', 'على', 'أن', 'يشمل', 'البلاغ', 'اسم', 'المبلغ', 'وبياناته', 'الشخصية', '\"', '.']\n",
            "وأشارت أن هذا القرار يأتي في إطار \"ضبط ما ينشر ويبث في وسائل الإعلام المختلفة ومواقع التواصل الاجتماعي من أخبار الكذب فيها متعمد وشائعات الغرض منها المساس بأمن البلاد (...) أو إلحاق الضرر بالمصلحة العامة للبلاد\".\n",
            "['وأشارت', 'أن', 'هذا', 'القرار', 'يأتي', 'في', 'إطار', '\"', 'ضبط', 'ما', 'ينشر', 'ويبث', 'في', 'وسائل', 'الإعلام', 'المختلفة', 'ومواقع', 'التواصل', 'الاجتماعي', 'من', 'أخبار', 'الكذب', 'فيها', 'متعمد', 'وشائعات', 'الغرض', 'منها', 'المساس', 'بأمن', 'البلاد', '(', '.', '.', '.', ')', 'أو', 'إلحاق', 'الضرر', 'بالمصلحة', 'العامة', 'للبلاد', '\"', '.']\n",
            "وكان النائب العام نبيل صادق قد أعلن في 28 شباط/فبراير الماضي أنه سيتخذ \"إجراءات جنائية\" ضد وسائل الإعلام وشبكات التواصل الاجتماعي بعد بث إذاعة بي بي سي تقريرا حول انتهاكات حقوق الإنسان قالت السلطات إنه يتضمن معلومات خاطئة.\n",
            "['وكان', 'النائب', 'العام', 'نبيل', 'صادق', 'قد', 'أعلن', 'في', '28', 'شباط', '/', 'فبراير', 'الماضي', 'أنه', 'سيتخذ', '\"', 'إجراءات', 'جنائية', '\"', 'ضد', 'وسائل', 'الإعلام', 'وشبكات', 'التواصل', 'الاجتماعي', 'بعد', 'بث', 'إذاعة', 'بي', 'بي', 'سي', 'تقريرا', 'حول', 'انتهاكات', 'حقوق', 'الإنسان', 'قالت', 'السلطات', 'إنه', 'يتضمن', 'معلومات', 'خاطئة', '.']\n",
            "للمزيد: رئاسيات مصر..\n",
            "['للمزيد', ':', 'رئاسيات', 'مصر', '.', '.']\n",
            "أي أداء للإعلام؟ وأصدر النائب العام في نفس الوقت قرارا بتكليف المحامين العامين ورؤساء النيابة العامة كل في منطقة عمله \"بمتابعة تلك الوسائل والمواقع وضبط ما يبث منها ويصدر عنها عمدا من أخبار أو بيانات أو إشاعات كاذبة\".\n",
            "['أي', 'أداء', 'للإعلام', '؟', 'وأصدر', 'النائب', 'العام', 'في', 'نفس', 'الوقت', 'قرارا', 'بتكليف', 'المحامين', 'العامين', 'ورؤساء', 'النيابة', 'العامة', 'كل', 'في', 'منطقة', 'عمله', '\"', 'بمتابعة', 'تلك', 'الوسائل', 'والمواقع', 'وضبط', 'ما', 'يبث', 'منها', 'ويصدر', 'عنها', 'عمدا', 'من', 'أخبار', 'أو', 'بيانات', 'أو', 'إشاعات', 'كاذبة', '\"', '.']\n",
            "وتضع السلطات أنشطة الإعلام وشبكات التواصل الاجتماعي تحت المجهر قبل قرابة أسبوعين من الانتخابات الرئاسية المقررة من 26 إلى 28 آذار/مارس الجاري.\n",
            "['وتضع', 'السلطات', 'أنشطة', 'الإعلام', 'وشبكات', 'التواصل', 'الاجتماعي', 'تحت', 'المجهر', 'قبل', 'قرابة', 'أسبوعين', 'من', 'الانتخابات', 'الرئاسية', 'المقررة', 'من', '26', 'إلى', '28', 'آذار', '/', 'مارس', 'الجاري', '.']\n",
            "وفي الأول من آذار/مارس الجاري، حذر الرئيس عبد الفتاح السيسي شخصيا وسائل الإعلام من السماح بـ\"الإساءة للجيش\" معتبرا أن هذا يوازي \"الخيانة العظمى\" في وقت تشن القوات المصرية عملية شاملة ضد تنظيم \"الدولة الإسلامية\" خصوصا في سيناء.\n",
            "['وفي', 'الأول', 'من', 'آذار', '/', 'مارس', 'الجاري', '،', 'حذر', 'الرئيس', 'عبد', 'الفتاح', 'السيسي', 'شخصيا', 'وسائل', 'الإعلام', 'من', 'السماح', 'بـ', '\"', 'الإساءة', 'للجيش', '\"', 'معتبرا', 'أن', 'هذا', 'يوازي', '\"', 'الخيانة', 'العظمى', '\"', 'في', 'وقت', 'تشن', 'القوات', 'المصرية', 'عملية', 'شاملة', 'ضد', 'تنظيم', '\"', 'الدولة', 'الإسلامية', '\"', 'خصوصا', 'في', 'سيناء', '.']\n",
            "ويذكر أن مصر حلت في المرتبة الـ161 (من 180 دولة) في الترتيب العالمي لحرية الصحافة خلال العام 2017 الذي أعدته منظمة \"مراسلون بلا حدود\".\n",
            "['ويذكر', 'أن', 'مصر', 'حلت', 'في', 'المرتبة', 'الـ161', '(', 'من', '180', 'دولة', ')', 'في', 'الترتيب', 'العالمي', 'لحرية', 'الصحافة', 'خلال', 'العام', '2017', 'الذي', 'أعدته', 'منظمة', '\"', 'مراسلون', 'بلا', 'حدود', '\"', '.']\n",
            "وفي مصر، هناك 29 صحافيا مسجونا، بحسب المنظمة نفسها.\n",
            "['وفي', 'مصر', '،', 'هناك', '29', 'صحافيا', 'مسجونا', '،', 'بحسب', 'المنظمة', 'نفسها', '.']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "#استخراج النص الإخباري من كل ملف بصيغة إكس إم إل\n",
        "def get_text_sentences(fpath0):\n",
        "  fopen0=open(fpath0)\n",
        "  content=fopen0.read()\n",
        "  fopen0.close()\n",
        "  new_content=content.split('<TEXT>')[1]\n",
        "  new_content=new_content.split(\"</TEXT>\")[0]\n",
        "  new_content=new_content.replace(\"#\",\"\") #handle hashtags\n",
        "  new_content=new_content.replace(\"_\",\" \")\n",
        "  new_content=re.sub(\"\\s+\",\" \",new_content)\n",
        "  lines0=new_content.split(\"\\n\")\n",
        "  sentences0=[]\n",
        "  for li0 in lines0:\n",
        "    li0=li0.strip()\n",
        "    if li0==\"\": continue\n",
        "    li0=li0.replace(\". \",\".\\n\")\n",
        "    li_split=li0.split(\"\\n\")\n",
        "    for li_sent in li_split: sentences0.append(li_sent.strip())\n",
        "  return sentences0\n",
        "\n",
        "#تقسيم أي نص إلى كلمات\n",
        "def tok(text0):\n",
        "  text0=re.sub(\"(\\W)\",r\" \\1 \",text0)\n",
        "  split0=re.split(\"\\s+\",text0)\n",
        "  return [v for v in split0 if v]\n",
        "\n",
        "#إزالة الحركات/التشكيل من الحروف تسهيلا للمعالجة\n",
        "ar_chars=[chr(i) for i in range(1560,1630)]\n",
        "diacritics1=[chr(i) for i in range(1552,1563)]\n",
        "diacritics2=[chr(i) for i in range(1611,1632)]\n",
        "full_arabic_diacritics=diacritics1+diacritics2\n",
        "\n",
        "def remove_diacritics(txt):\n",
        "  filtered=[v for v in txt if not v in full_arabic_diacritics]\n",
        "  return \"\".join(filtered)\n",
        "\n",
        "\n",
        "#التعرف على علامات الترقيم\n",
        "def is_punct(token):\n",
        "  if len(token)==0: return True\n",
        "  unicode_check=unicodedata.category(token[0])\n",
        "  if len(unicode_check)>0: return unicode_check[0]==\"P\"\n",
        "  #print(token, unicode_check)\n",
        "  return True\n",
        "\n",
        "\n",
        "#تطبيق الدوال الواردة أعلاه على أحد النصوص للتأكد من عملها جيدا  \n",
        "fpath=ant_file_list[16050][1]\n",
        "cur_sentences=get_text_sentences(fpath)\n",
        "for sent0 in cur_sentences:\n",
        "  print(sent0)\n",
        "  print(tok(sent0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thUehNpA6gXw"
      },
      "source": [
        "ثم بعد ذلك إنشاء ملف التبويب الخاص بهذه النوعية من البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ww4IOBMuMDf",
        "outputId": "9f48630e-44d6-4583-dae0-e95105549d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26\n",
            "عدد الكلمات التي تمت كتابتها لملف التبويب 41288\n",
            "annotation file saved successfully arabic-news-annotation.csv\n"
          ]
        }
      ],
      "source": [
        "import csv \n",
        "from string import punctuation\n",
        "import string\n",
        "\n",
        "#لن نستخدم كل البيانات في التبويب، وإنما فقط أول خمس ملفات في كل فئة\n",
        "n_files_per_category=5\n",
        "grouped_files=[(key,[v[1] for v in list(group)]) for key,group in groupby(ant_file_list,lambda x:x[0])]\n",
        "print(len(grouped_files))\n",
        "annotation_list=[]\n",
        "for k0,grp0 in grouped_files:\n",
        "  #print(k0)\n",
        "  for cur_fpath in grp0[:n_files_per_category]: \n",
        "    #print(cur_fpath)\n",
        "    fname=os.path.split(cur_fpath)[1]\n",
        "    fname=fname.replace(\".txt\",\"\")\n",
        "    cur_sentences=get_text_sentences(cur_fpath) \n",
        "    for s_i, sent0 in enumerate(cur_sentences):\n",
        "      cur_sent_id=\"%s-%s-%s\"%(k0,fname, s_i)\n",
        "      cur_sent_id=cur_sent_id.replace(\"/\",\"-\")\n",
        "      sent0=remove_diacritics(sent0)\n",
        "      cur_sent_tokens=tok(sent0)\n",
        "      for token0 in cur_sent_tokens:\n",
        "        tag=\"\"\n",
        "        if is_punct(token0): tag=\"Punctuation\"\n",
        "        if token0[0].isdigit(): tag=\"Number\"\n",
        "        if token0[0] in string.ascii_letters: tag=\"Foreign\"\n",
        "        annotation_list.append((cur_sent_id,token0,tag))\n",
        "\n",
        "annotation_file_name=\"arabic-news-annotation.csv\"\n",
        "with open(annotation_file_name, 'w') as fopen: \n",
        "    write = csv.writer(fopen) \n",
        "    write.writerows(annotation_list) \n",
        "\n",
        "#print(\"full_punctuation\", full_punctuation)\n",
        "print(\"عدد الكلمات التي تمت كتابتها لملف التبويب\", len(annotation_list))\n",
        "print(\"annotation file saved successfully\",annotation_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NESNlnDU76cm"
      },
      "source": [
        "ثم إنشاء ملف نصي للجمل المقسمة إلى كلمات، لاستخدامها في تدريب متجه الكلمات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk0cX3Nv8Obt",
        "outputId": "2ff10202-14bd-4a87-f529-7876feeebd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "عدد الجمل المستخدمة 14201\n",
            "saved text file successfully: tokenized-text/news.txt\n"
          ]
        }
      ],
      "source": [
        "n_files_per_category=50\n",
        "#هذا هو عدد الملفات التي نأخذها من كل فئة، يمكننا استخدام المزيد\n",
        "grouped_files=[(key,[v[1] for v in list(group)]) for key,group in groupby(ant_file_list,lambda x:x[0])]\n",
        "tokenized_sentence_list=[]\n",
        "for k0,grp0 in grouped_files:\n",
        "  for cur_fpath in grp0[:n_files_per_category]: \n",
        "    #print(cur_fpath)\n",
        "    fname=os.path.split(cur_fpath)[1]\n",
        "    fname=fname.replace(\".txt\",\"\")\n",
        "    cur_sentences=get_text_sentences(cur_fpath) \n",
        "    for s_i, sent0 in enumerate(cur_sentences):\n",
        "      cur_sent_id=\"%s-%s-%s\"%(k0,fname, s_i)\n",
        "      cur_sent_id=cur_sent_id.replace(\"/\",\"-\")\n",
        "      sent0=remove_diacritics(sent0)\n",
        "      cur_sent_tokens=tok(sent0)\n",
        "      tokenized_sentence_list.append(cur_sent_tokens)\n",
        "\n",
        "print(\"عدد الجمل المستخدمة\",len(tokenized_sentence_list))\n",
        "import os\n",
        "text_dir=\"tokenized-text\"\n",
        "if not os.path.exists(text_dir): os.makedirs(text_dir)\n",
        "cur_fname=\"news.txt\"\n",
        "cur_fpath=os.path.join(text_dir,cur_fname)\n",
        "cur_fopen=open(cur_fpath,\"w\")\n",
        "for line_tokens in tokenized_sentence_list:\n",
        "  cur_line=\" \".join(line_tokens)\n",
        "  cur_fopen.write(cur_line+\"\\n\")\n",
        "cur_fopen.close()\n",
        "print(\"saved text file successfully:\", cur_fpath)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Zha0a0-Gya"
      },
      "source": [
        "##ثالثا - إنشاء متجه الكلمات\n",
        "*  نستخدم هنا مكتبة gensim\n",
        "*  إذا لم تكن المكتبة موجودة على جوجل كولاب، يمكن تثبيتها من خلال ما يلي:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmEiuLuD-PrK",
        "outputId": "4ea958f2-d9e9-4057-8243-92ac5632cca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI8SrOR2-z96",
        "outputId": "39708da3-2595-4868-de76-b547752a2c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "عدد الجمل المستخدمة 21059\n",
            "saved model successfully: wv/arabic_quran_news_wv_model_300.wv elapsed 289.64\n"
          ]
        }
      ],
      "source": [
        "import gensim, os, time\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "word_vector_fname=\"arabic_quran_news_wv_model_300.wv\"\n",
        "\n",
        "all_tokenized_sentences=[]\n",
        "root_dir=\"tokenized-text\"\n",
        "wv_dir=\"wv\"\n",
        "if not os.path.exists(wv_dir): os.makedirs(wv_dir)\n",
        "wv_model_fpath=os.path.join(wv_dir,word_vector_fname)\n",
        "for fname in os.listdir(root_dir):\n",
        "  fpath=os.path.join(root_dir,fname)\n",
        "  fopen=open(fpath)\n",
        "  for line0 in fopen:\n",
        "    split0=line0.strip().split(\" \")\n",
        "    all_tokenized_sentences.append(split0)\n",
        "  fopen.close()\n",
        "\n",
        "random.shuffle(all_tokenized_sentences)  \n",
        "print(\"عدد الجمل المستخدمة\", len(all_tokenized_sentences))\n",
        "t0=time.time()\n",
        "arabic_quran_news_model=gensim.models.Word2Vec(\n",
        "        all_tokenized_sentences,\n",
        "        size=300,\n",
        "        window=10,\n",
        "        min_count=2,\n",
        "        workers=10,\n",
        "        iter=200)\n",
        "arabic_quran_news_model.save(wv_model_fpath)\n",
        "t1=time.time()\n",
        "elapsed=round(t1-t0,2)\n",
        "print(\"saved model successfully:\", wv_model_fpath, \"elapsed\",elapsed)\n",
        "# quran_model.most_similar(\"موسى\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vM0rqPVYAGwj"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "arabic_quran_news_model.most_similar(\"العراق\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3nV3jvvu59C",
        "outputId": "dacaa41e-8375-4722-d1df-e46009022a84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arabic_quran_news_model.vector_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpXKfP0bRM7w",
        "outputId": "ff5c4d55-f1ab-4029-d8b9-e682fae13f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-26 13:38:00--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/arabic_w2v_cc_300d_ar_2.7.0_2.4_1607168354606.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.132.128\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.132.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1232487758 (1.1G) [application/octet-stream]\n",
            "Saving to: ‘arabic_w2v_cc_300d_ar_2.7.0_2.4_1607168354606.zip’\n",
            "\n",
            "arabic_w2v_cc_300d_ 100%[===================>]   1.15G  21.4MB/s    in 47s     \n",
            "\n",
            "2022-05-26 13:38:47 (25.0 MB/s) - ‘arabic_w2v_cc_300d_ar_2.7.0_2.4_1607168354606.zip’ saved [1232487758/1232487758]\n",
            "\n",
            "--2022-05-26 13:38:47--  http://wv/arabic_w2v_cc_300d\n",
            "Resolving wv (wv)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wv’\n",
            "FINISHED --2022-05-26 13:38:47--\n",
            "Total wall clock time: 47s\n",
            "Downloaded: 1 files, 1.1G in 47s (25.0 MB/s)\n"
          ]
        }
      ],
      "source": [
        " !wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/arabic_w2v_cc_300d_ar_2.7.0_2.4_1607168354606.zip wv/arabic_w2v_cc_300d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6g7wFRbCCYE"
      },
      "source": [
        "#القسم الثاني - تعريف وتدريب الشبكة العصبية وإنشاء نموذج\n",
        "يشمل هذا القسم قراءة الملفات المبوبة الموجودة على جوجل شيت، وإنشاء الكود الخاص باستخراج السمات من الكلمات، وتحويل الكلمات والمسميات إلى متجهات قابلة لتغذية الشبكة العصبية بها، ويشمل أيضا تعريف الشبكة العصبية وبارمتراتها، ثم بدء التدريب على البيانات المتاحة."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgb9FrIwDDYg"
      },
      "source": [
        "##أولا - الكود الخاص بتحويل العناصر المختلفة إلى أرقام لتغذية الشبكة العصبية بها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh_tG80IKD8q",
        "outputId": "667751f0-aa03-4133-ec01-4313d9976eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "868 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ],
      "source": [
        "ar_chars=[chr(i) for i in range(1560,1630)]\n",
        "ar_chars+=\" \"\n",
        "\n",
        "#تحويل المسميات غير الرقمية (الفئات) إلى متجه صفري ليس به إلا واحد فقط مناظر لترتيب العنصر الحالي ضمن قائمة الفئات\n",
        "def one_hot_encoder(item,item_list):\n",
        "  zeros=[0.]*len(item_list)\n",
        "  if item in item_list:\n",
        "    item_index=item_list.index(item)\n",
        "    zeros[item_index]=1.\n",
        "  return zeros\n",
        "#استخدام سمات الحروف التي تبدأ بها وتنتهي بها الكلمة لعمل متجه من الأرقام بالسمات المميزة للكلمة سيتم تغذية الشبكة العصبية بها\n",
        "def extract_word_feature_NEW(word0,n_chars=3):\n",
        "  feature_list=[]\n",
        "  flat_feature_list=[]\n",
        "  for i in range(n_chars):\n",
        "    cur_char=\" \"\n",
        "    if i<len(word0): cur_char=word0[i]\n",
        "    cur_one_hot=one_hot_encoder(cur_char,ar_chars)\n",
        "    flat_feature_list.extend(cur_one_hot)\n",
        "  for i in range(n_chars):\n",
        "    word1 =word0[-n_chars:] \n",
        "    cur_char=\" \"\n",
        "    if i<len(word1): cur_char=word1[i]\n",
        "    cur_one_hot=one_hot_encoder(cur_char,ar_chars)\n",
        "    flat_feature_list.extend(cur_one_hot)\n",
        "  return flat_feature_list\n",
        "\n",
        "\n",
        "def extract_word_features(word0,params0={},additional_data=[]):\n",
        "  n_chars=params0.get(\"n_chars\",3)\n",
        "  wv_model_fpath=params0.get(\"wv_model_path\")\n",
        "  wv_model=wv_dict[wv_model_fpath]\n",
        "  feature_list=[]\n",
        "  flat_feature_list=[]\n",
        "  for i in range(n_chars):\n",
        "    cur_char=\" \"\n",
        "    if i<len(word0): cur_char=word0[i]\n",
        "    cur_one_hot=one_hot_encoder(cur_char,ar_chars)\n",
        "    flat_feature_list.extend(cur_one_hot)\n",
        "  for i in range(n_chars):\n",
        "    word1 =word0[-n_chars:] \n",
        "    cur_char=\" \"\n",
        "    if i<len(word1): cur_char=word1[i]\n",
        "    cur_one_hot=one_hot_encoder(cur_char,ar_chars)\n",
        "    flat_feature_list.extend(cur_one_hot)\n",
        "  if wv_model!=None:\n",
        "    try:\n",
        "      cur_vec=wv_model[word0]\n",
        "    except:\n",
        "      cur_vec=[0.]*wv_model.vector_size\n",
        "    flat_feature_list.extend(cur_vec)\n",
        "  flat_feature_list.extend(additional_data)\n",
        "\n",
        "  return flat_feature_list\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "wv_dict={} #global variable - we will need to improve the implementation here\n",
        "wv_dict[wv_fpath]=arabic_quran_news_model\n",
        "\n",
        "cur_params={}\n",
        "cur_params[\"n_chars\"]=4\n",
        "cur_params[\"wv_model_path\"]=wv_fpath\n",
        "\n",
        "\n",
        "word=\"فأسقيناكموه\"\n",
        "# fl0=extract_word_feature_NEW(word)\n",
        "# print(len(fl0),fl0[:50])\n",
        "\n",
        "fl0=extract_word_features(word,cur_params)\n",
        "print(len(fl0),fl0[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F15-UoZQLzkW"
      },
      "source": [
        "## ثانيا - تعريف الشبكة العصبية التكرارية المستخدمة\n",
        "Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il6cVKh6MEQR",
        "outputId": "1b0046d7-087a-4a0c-cdb0-6d7cb9ab7cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor shape torch.Size([10, 5])\n",
            "output tensor shape torch.Size([10, 2])\n",
            "feature_tensor torch.Size([4, 3])\n",
            "label_tensor torch.Size([4, 2])\n",
            "RNN(\n",
            "  (lstm): LSTM(3, 64, num_layers=2)\n",
            "  (hidden2out): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "#Let's build the network - here is a small cheat sheet for possible RNN classes based on input and output size\n",
        "#https://github.com/hmghaly/rnn/blob/master/classes.py\n",
        "\n",
        "#here the size of the output is the same as the size of the input\n",
        "#the depth of the output depends on the number of possible outcome categories (e.g. different phonemes)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import dill as pickle\n",
        "import numpy as np\n",
        "#from code_utils import np_lstm\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "#device = torch.device('cuda')\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size,num_layers, matching_in_out=False, apply_sigmoid=False, apply_softmax=False, batch_size=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.apply_softmax=apply_softmax\n",
        "    self.apply_sigmoid=apply_sigmoid\n",
        "    self.matching_in_out = matching_in_out #length of input vector matches the length of output vector \n",
        "    self.lstm = nn.LSTM(input_size, hidden_size,num_layers)\n",
        "    self.hidden2out = nn.Linear(hidden_size, output_size)\n",
        "    if self.apply_softmax: self.softmax =nn.Softmax(dim=2)\n",
        "    if self.apply_sigmoid: self.sigmoid =nn.Sigmoid() \n",
        "    \n",
        "    #self.sigmoid = torch.sigmoid(dim=1)\n",
        "    self.hidden = self.init_hidden()\n",
        "  def forward(self, feature_list):\n",
        "    self.hidden = self.init_hidden() ### check\n",
        "    feature_list=torch.tensor(feature_list)\n",
        "    feature_list=feature_list.to(device) #### <<<<<<<<<<<<<<<<< \n",
        "    if self.matching_in_out:\n",
        "      lstm_out, _ = self.lstm( feature_list.view(len( feature_list), 1, -1))\n",
        "      output_scores = self.hidden2out(lstm_out.view(len( feature_list), -1))\n",
        "      if self.apply_sigmoid: output_scores=self.sigmoid(output_scores).to(device)\n",
        "      elif self.apply_softmax: output_scores=self.softmax(output_scores).to(device)\n",
        "      #output_scores = torch.sigmoid(output_space) #we'll need to check if we need this sigmoid\n",
        "      return output_scores #output_scores\n",
        "    else:\n",
        "      outs=[]\n",
        "      for i in range(len(feature_list)):\n",
        "        cur_ft_tensor=feature_list[i]#.view([1,1,self.input_size])\n",
        "        cur_ft_tensor=cur_ft_tensor.view([1,1,self.input_size])\n",
        "        lstm_out, self.hidden = self.lstm(cur_ft_tensor, self.hidden)\n",
        "        outs=self.hidden2out(lstm_out)\n",
        "        if self.apply_sigmoid: outs = self.sigmoid(outs).to(device) #self.sigmoid =nn.Sigmoid()\n",
        "        elif self.apply_softmax: outs = self.softmax(outs).to(device)\n",
        "        \n",
        "      return outs\n",
        "  def init_hidden(self):\n",
        "    #return torch.rand(self.num_layers, self.batch_size, self.hidden_size)\n",
        "    return (torch.rand(self.num_layers, self.batch_size, self.hidden_size).to(device),\n",
        "            torch.rand(self.num_layers, self.batch_size, self.hidden_size).to(device))\n",
        "\n",
        "\n",
        "def out2labels(rnn_flat_out,label_list): #a flat rnn output to split into slices, and get the label weights for each slice\n",
        "  final_list=[]\n",
        "  n_slices=int(len(rnn_flat_out)/len(label_list))\n",
        "  for i0 in range(n_slices):\n",
        "    i1=i0+1\n",
        "    cur_slice=rnn_flat_out[i0*len(label_list):i1*len(label_list)]\n",
        "    tmp_list=[]\n",
        "    for lb0,cs0 in zip(label_list,cur_slice): tmp_list.append((lb0,cs0))\n",
        "    tmp_list.sort(key=lambda x:-x[-1])\n",
        "    final_list.append(tmp_list)\n",
        "  return final_list\n",
        "\n",
        "\n",
        "class model_pred:\n",
        "  def __init__(self,model_fpath0) -> None:\n",
        "    # try: self.checkpoint = torch.load(model_fpath0)\n",
        "    # except: self.checkpoint = dill_unpickle(model_fpath0)\n",
        "    self.checkpoint = torch.load(model_fpath0)\n",
        "    self.rnn = RNN(self.checkpoint[\"n_input\"], self.checkpoint[\"n_hidden\"] , self.checkpoint[\"n_output\"] , self.checkpoint[\"n_layers\"] , matching_in_out=self.checkpoint[\"n_layers\"]).to(device)\n",
        "    self.rnn.load_state_dict(self.checkpoint['model_state_dict'])\n",
        "    self.rnn.eval()\n",
        "    #self.feature_extraction_fn=self.checkpoint[\"feature_extraction_function\"]\n",
        "    self.feature_extraction_params=self.checkpoint[\"feature_extraction_parameters\"]\n",
        "    self.labels=self.checkpoint[\"labels\"]\n",
        "\n",
        "    # self.standard_labels=self.checkpoint['label_extraction_parameters']['ipa_ft_list']\n",
        "    # self.ipa_ft_dict=self.checkpoint[\"label_extraction_parameters\"][\"ipa_ft_dict\"]\n",
        "    # self.ipa_list=self.checkpoint[\"label_extraction_parameters\"][\"ipa_symbol_list\"]    \n",
        "  def predict(self,item_fpath):\n",
        "    times,ft_vector=self.feature_extraction_fn(item_fpath,self.feature_extraction_params)\n",
        "    ft_tensor=torch.tensor(ft_vector,dtype=torch.float32)\n",
        "    rnn_out= self.rnn(ft_tensor)\n",
        "    preds0=out2labels(rnn_out.ravel(),self.labels)\n",
        "    times_preds_list=[]\n",
        "    for pr0,ti0 in zip(preds0,times):\n",
        "      pr0=[(v[0],v[1].item()) for v in pr0]\n",
        "      times_preds_list.append((ti0,pr0)) \n",
        "    return times_preds_list  \n",
        "\n",
        "\n",
        "\n",
        "n_input=5\n",
        "n_hidden =64\n",
        "n_layers=2\n",
        "n_output=2\n",
        "LR=0.01\n",
        "loss_func = nn.MSELoss()\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers,matching_in_out=True).to(device)\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
        "\n",
        "n_data_points=10\n",
        "input_tensor=torch.rand((n_data_points, n_input)).to(device)\n",
        "output = rnn(input_tensor)\n",
        "print(\"input tensor shape\", input_tensor.shape)\n",
        "#print(output)\n",
        "print(\"output tensor shape\", output.shape)\n",
        "\n",
        "feature_list=[(0,3,0),(2,1,0),(1,0,0),(5,0,0)]\n",
        "label_list=[(0,1),(1,0),(0,0),(1,0)]\n",
        "feature_tensor=torch.tensor(feature_list,dtype=torch.float32).to(device)\n",
        "label_tensor=torch.tensor(label_list,dtype=torch.float32).to(device)\n",
        "print(\"feature_tensor\",feature_tensor.shape)\n",
        "print(\"label_tensor\",label_tensor.shape)\n",
        "n_input=feature_tensor.shape[1]\n",
        "n_hidden =64\n",
        "n_layers=2\n",
        "n_output=label_tensor.shape[1]\n",
        "LR=0.01\n",
        "loss_func = nn.MSELoss()\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers,matching_in_out=True).to(device)\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR) \n",
        "\n",
        "print(rnn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzBjxkmQj-AQ"
      },
      "source": [
        "## ثالثا - قراءة ملفات التبويب\n",
        "قراءة ملف التبويب وتحويل الصفوف المبوبة إلى صيغة \n",
        "json\n",
        " - نقوم بذلك كل مرة يتم فيها تحديث التبويب"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcfh0qKGmqPl"
      },
      "source": [
        "### 1- نقرأ أولا ملف تبويب النص القرآني"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkdZYQ7Ib-gX",
        "outputId": "32a29c1d-2134-46af-cff8-e969077ac4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['quran-annotation-simple', 'verb-types', 'Tags', 'Prepositions'])\n",
            "Index(['sura-aya', 'word', 'length', 'POS', 'prefix_size', 'suffix_size',\n",
            "       'prefix_infix', 'suffix_infix_size', 'removed_prefix',\n",
            "       'stem_removed_suffix', 'stem + pre_infix', 'stem', 'lemma', 'Frame',\n",
            "       'Type', 'verb-preposition', 'verb-preposition2'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "annotated_dir=\"annotated\"\n",
        "annotated_data_dir=os.path.join(annotated_dir,\"data\")\n",
        "if not os.path.exists(annotated_data_dir): os.makedirs(annotated_data_dir)\n",
        "annotated_meta_dir=os.path.join(annotated_dir,\"meta\")\n",
        "if not os.path.exists(annotated_meta_dir): os.makedirs(annotated_meta_dir)\n",
        "\n",
        "\n",
        "#ملف التبويب الخاص بالنص القرآني\n",
        "annotation_xls='https://docs.google.com/spreadsheets/d/e/2PACX-1vR4PyLjLWZlAThzse1t_JDPWqXd1i6sSb8NE1lVoCg-sCN8lDg4oDu50jghsrRWq7xepNqUqWa3Q7to/pub?output=xlsx'\n",
        "cur_workbook_obj=pd.read_excel(annotation_xls, None,keep_default_na=False, dtype=str)\n",
        "print(cur_workbook_obj.keys())\n",
        "cur_sheet_obj=cur_workbook_obj[\"quran-annotation-simple\"]\n",
        "tags_sheet_obj=cur_workbook_obj[\"Tags\"]\n",
        "verb_types_sheet_obj=cur_workbook_obj[\"verb-types\"]\n",
        "\n",
        "print(cur_sheet_obj.keys())\n",
        "new_list=[]\n",
        "annotation_fname=\"quran-annotation-output.txt\"\n",
        "annotation_output_fpath=os.path.join(annotated_data_dir,annotation_fname)\n",
        "annotation_output_fopen=open(annotation_output_fpath,\"w\")\n",
        "for i,row_dict in cur_sheet_obj.iterrows():\n",
        "  if row_dict.get(\"POS\",\"\")==\"\": break \n",
        "  line=\"%s\\n\"%(json.dumps(dict(row_dict)))\n",
        "  annotation_output_fopen.write(line)\n",
        "annotation_output_fopen.close()  \n",
        "\n",
        "annotation_tags_fname=\"quran-annotation-tags.txt\"\n",
        "annotated_tags_fpath=os.path.join(annotated_meta_dir, annotation_tags_fname)\n",
        "tags_output_fopen=open(annotated_tags_fpath,\"w\")\n",
        "cur_tag_list=list(tags_sheet_obj[\"Tag\"])\n",
        "tags_output_fopen.write(json.dumps(cur_tag_list))\n",
        "tags_output_fopen.close()\n",
        "\n",
        "annotation_frames_fname=\"quran-annotation-frames.txt\"\n",
        "annotated_frames_fpath=os.path.join(annotated_meta_dir, annotation_frames_fname)\n",
        "frames_output_fopen=open(annotated_frames_fpath,\"w\")\n",
        "cur_frame_list=list(verb_types_sheet_obj[\"Frame\"])\n",
        "cur_frame_list.append(\"\")\n",
        "frames_output_fopen.write(json.dumps(cur_frame_list))\n",
        "frames_output_fopen.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cMJ_76cK-6O"
      },
      "source": [
        "### 2- نفس الشيء مع ملف تبويب النص الإخباري"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvTrdj7ab2QG",
        "outputId": "b0a47906-8a51-487b-fca3-68b93a824f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['arabic-news-annotation', 'Tags', 'verb-types', 'Prepositions'])\n",
            "Index(['sentence-id', 'word', 'POS', 'prefix_size', 'suffix_size',\n",
            "       'prefix_infix', 'suffix_infix_size', 'removed_prefix',\n",
            "       'stem_removed_suffix', 'stem + pre_infix', 'stem', 'lemma', 'Frame',\n",
            "       'verb-preposition'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "annotated_dir=\"annotated\"\n",
        "annotated_data_dir=os.path.join(annotated_dir,\"data\")\n",
        "if not os.path.exists(annotated_data_dir): os.makedirs(annotated_data_dir)\n",
        "annotated_meta_dir=os.path.join(annotated_dir,\"meta\")\n",
        "if not os.path.exists(annotated_meta_dir): os.makedirs(annotated_meta_dir)\n",
        "\n",
        "\n",
        "#ملف التبويب الخاص بالنص الإخباري\n",
        "annotation_xls='https://docs.google.com/spreadsheets/d/e/2PACX-1vSGupLste1JpJ-VoQtP4qkNB0APBoy6HghB9ikJzYFDUI30spjpl0oVEnsOS9-bcYaDz_dAayvASoOS/pub?output=xlsx'\n",
        "cur_workbook_obj=pd.read_excel(annotation_xls, None,keep_default_na=False, dtype=str)\n",
        "print(cur_workbook_obj.keys())\n",
        "cur_sheet_obj=cur_workbook_obj[\"arabic-news-annotation\"]\n",
        "tags_sheet_obj=cur_workbook_obj[\"Tags\"]\n",
        "verb_types_sheet_obj=cur_workbook_obj[\"verb-types\"]\n",
        "\n",
        "print(cur_sheet_obj.keys())\n",
        "new_list=[]\n",
        "annotation_fname=\"news-annotation-output.txt\"\n",
        "annotation_output_fpath=os.path.join(annotated_data_dir,annotation_fname)\n",
        "annotation_output_fopen=open(annotation_output_fpath,\"w\")\n",
        "for i,row_dict in cur_sheet_obj.iterrows():\n",
        "  if row_dict.get(\"POS\",\"\")==\"\": break \n",
        "  line=\"%s\\n\"%(json.dumps(dict(row_dict)))\n",
        "  annotation_output_fopen.write(line)\n",
        "annotation_output_fopen.close()  \n",
        "\n",
        "annotation_tags_fname=\"news-annotation-tags.txt\"\n",
        "annotated_tags_fpath=os.path.join(annotated_meta_dir, annotation_tags_fname)\n",
        "tags_output_fopen=open(annotated_tags_fpath,\"w\")\n",
        "cur_tag_list=list(tags_sheet_obj[\"Tag\"])\n",
        "tags_output_fopen.write(json.dumps(cur_tag_list))\n",
        "tags_output_fopen.close()\n",
        "\n",
        "annotation_frames_fname=\"news-annotation-frames.txt\"\n",
        "annotated_frames_fpath=os.path.join(annotated_meta_dir, annotation_frames_fname)\n",
        "frames_output_fopen=open(annotated_frames_fpath,\"w\")\n",
        "cur_frame_list=list(verb_types_sheet_obj[\"Frame\"])\n",
        "cur_frame_list.append(\"\")\n",
        "frames_output_fopen.write(json.dumps(cur_frame_list))\n",
        "frames_output_fopen.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3- قراءة ملف التبويب الخارجي"
      ],
      "metadata": {
        "id": "HVYuoYtUXPnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ملف التبويب الخاص بالنص الإخباري الخارجي المبوب\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "annotated_dir=\"annotated\"\n",
        "annotated_data_dir=os.path.join(annotated_dir,\"data\")\n",
        "if not os.path.exists(annotated_data_dir): os.makedirs(annotated_data_dir)\n",
        "annotated_meta_dir=os.path.join(annotated_dir,\"meta\")\n",
        "if not os.path.exists(annotated_meta_dir): os.makedirs(annotated_meta_dir)\n",
        "\n",
        "\n",
        "#ملف التبويب الخاص بالنص الإخباري الخارجي\n",
        "annotation_xls='https://docs.google.com/spreadsheets/d/e/2PACX-1vShuFKVslVSUlbB6FjAO0ZBFh1fMbopAT1z0fYG48uGktEnbjNrKJ8ELCjDm6t6UTKp142Z233c2fE7/pub?output=xlsx'\n",
        "cur_workbook_obj=pd.read_excel(annotation_xls, None,keep_default_na=False, dtype=str)\n",
        "print(cur_workbook_obj.keys())\n",
        "cur_sheet_obj=cur_workbook_obj[\"Sheet1\"]\n",
        "tags_sheet_obj=cur_workbook_obj[\"Tags\"]\n",
        "verb_types_sheet_obj=cur_workbook_obj[\"verb-types\"]\n",
        "\n",
        "print(cur_sheet_obj.keys())\n",
        "new_list=[]\n",
        "annotation_fname=\"external-annotation-output.txt\"\n",
        "annotation_output_fpath=os.path.join(annotated_data_dir,annotation_fname)\n",
        "annotation_output_fopen=open(annotation_output_fpath,\"w\")\n",
        "for i,row_dict in cur_sheet_obj.iterrows():\n",
        "  if row_dict.get(\"POS\",\"\")==\"\": break \n",
        "  line=\"%s\\n\"%(json.dumps(dict(row_dict)))\n",
        "  annotation_output_fopen.write(line)\n",
        "annotation_output_fopen.close()  \n",
        "\n",
        "annotation_tags_fname=\"external-annotation-tags.txt\"\n",
        "annotated_tags_fpath=os.path.join(annotated_meta_dir, annotation_tags_fname)\n",
        "tags_output_fopen=open(annotated_tags_fpath,\"w\")\n",
        "cur_tag_list=list(tags_sheet_obj[\"Tag\"])\n",
        "tags_output_fopen.write(json.dumps(cur_tag_list))\n",
        "tags_output_fopen.close()\n",
        "\n",
        "annotation_frames_fname=\"external-annotation-frames.txt\"\n",
        "annotated_frames_fpath=os.path.join(annotated_meta_dir, annotation_frames_fname)\n",
        "frames_output_fopen=open(annotated_frames_fpath,\"w\")\n",
        "cur_frame_list=list(verb_types_sheet_obj[\"Frame\"])\n",
        "cur_frame_list.append(\"\")\n",
        "frames_output_fopen.write(json.dumps(cur_frame_list))\n",
        "frames_output_fopen.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-esmIOzWTez",
        "outputId": "da2bb211-86b0-4e34-913b-04d6a6d88dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['Sheet1', 'Tags', 'verb-types', 'Prepositions'])\n",
            "Index(['Unnamed: 0', 'sentence_id', 'word', 'POS', 'prefix_size',\n",
            "       'suffix_size', 'lemma', 'Frame', 'verb-preposition'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uiqP3qyp4qx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o59A6uz5psjo"
      },
      "source": [
        "## رابعا - قراءة وتجهيز البيانات المبوبة لتغذية الشبكة بها\n",
        "بالنسبة لبيانات أقسام الكلام"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k12BpKF-eBjH",
        "outputId": "92cc490c-0251-4712-9e9d-a06d4b9bbb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quran_data (number of ayas) 295\n",
            "news_data (number of sentences) 30\n",
            "external_data (number of sentences) 1000\n",
            "combined_train_data 993\n",
            "combined_test_data 332\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from itertools import groupby\n",
        "import random\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "annotated_dir=\"annotated\"\n",
        "annotated_data_dir=os.path.join(annotated_dir,\"data\")\n",
        "annotated_meta_dir=os.path.join(annotated_dir,\"meta\")\n",
        "\n",
        "def read_group_data(data_fpath0,col1_header,col2_header,grouping_header_name):\n",
        "  annotation_output_fopen=open(data_fpath0)\n",
        "  all_row_data=[]\n",
        "  for line in annotation_output_fopen:\n",
        "    json_dict=json.loads(line.strip())\n",
        "    all_row_data.append(json_dict)\n",
        "  annotation_output_fopen.close() \n",
        "  raw_sent_data=[list(group) for key,group in groupby(all_row_data,lambda x:x[grouping_header_name])]\n",
        "  all_data0=[]\n",
        "  for sent0 in raw_sent_data:\n",
        "    cur_sent_item=[(s0[col1_header], s0[col2_header]) for s0 in sent0]\n",
        "    all_data0.append(cur_sent_item)\n",
        "  return all_data0\n",
        "\n",
        "def read_json(json_fpath0):\n",
        "  fopen0=open(json_fpath0)\n",
        "  json_content=json.load(fopen0)\n",
        "  fopen0.close()\n",
        "  return json_content  \n",
        "\n",
        "def split_train_test(data0,train_ratio0=0.75):\n",
        "  train_size=int(train_ratio0*len(data0))\n",
        "  train_data=data0[:train_size]\n",
        "  test_data=data0[train_size:]\n",
        "  return train_data, test_data\n",
        "\n",
        "quran_annotation_fname=\"quran-annotation-output.txt\"\n",
        "news_annotation_fname=\"news-annotation-output.txt\"\n",
        "external_annotation_fname=\"external-annotation-output.txt\"\n",
        "\n",
        "annotation_tags_fname=\"quran-annotation-tags.txt\"\n",
        "\n",
        "tag_fpath=os.path.join(annotated_meta_dir,annotation_tags_fname)\n",
        "\n",
        "\n",
        "pos_tags=read_json(tag_fpath)\n",
        "# annotated_dir=\"annotated\"\n",
        "# annotated_meta_dir=os.path.join(annotated_dir,\"meta\")\n",
        "annotation_frames_fname=\"quran-annotation-frames.txt\"\n",
        "frame_fpath=os.path.join(annotated_meta_dir,annotation_frames_fname)\n",
        "frame_list=read_json(frame_fpath)\n",
        "\n",
        "quran_annotation_fpath=os.path.join(annotated_data_dir,quran_annotation_fname)\n",
        "news_annotation_fpath=os.path.join(annotated_data_dir,news_annotation_fname)\n",
        "external_annotation_fpath=os.path.join(annotated_data_dir,external_annotation_fname)\n",
        "\n",
        "\n",
        "quran_data= read_group_data(quran_annotation_fpath,\"word\",\"POS\",\"sura-aya\") \n",
        "news_data= read_group_data(news_annotation_fpath,\"word\",\"POS\",\"sentence-id\")\n",
        "external_data=read_group_data(external_annotation_fpath,\"word\",\"POS\",\"sentence_id\")\n",
        "\n",
        "external_data=external_data[:1000] \n",
        "\n",
        "quran_train_data,quran_test_data=split_train_test(quran_data)\n",
        "news_train_data,news_test_data=split_train_test(news_data)\n",
        "external_train_data,external_test_data=split_train_test(external_data)\n",
        "\n",
        "train_data=quran_train_data+news_train_data+external_train_data\n",
        "test_data=quran_test_data+news_test_data+external_test_data\n",
        "\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(test_data)\n",
        "\n",
        "print(\"quran_data (number of ayas)\", len(quran_data))\n",
        "print(\"news_data (number of sentences)\", len(news_data))\n",
        "print(\"external_data (number of sentences)\", len(external_data))\n",
        "print(\"combined_train_data\",len(train_data))\n",
        "print(\"combined_test_data\",len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRSbYUiJol22"
      },
      "source": [
        "## خامسا - بدء التدريب باستخدام الشبكة العصبية"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- التعرف على عدد المدخلات والمخرجات"
      ],
      "metadata": {
        "id": "rsPIJZ0FXDxL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSBkOkPZub0L",
        "outputId": "72002981-94ce-4f91-b382-1134df3f43e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([36, 868])\n",
            "torch.Size([36, 18])\n",
            "n_input 868\n",
            "n_output 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ],
      "source": [
        "#التعرف على عدد مدخلات ومخرجات الشبكة من واقع عدد السمات والمسميات\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "\n",
        "wv_dict={} #global variable - we will need to improve the implementation here\n",
        "wv_dict[wv_fpath]=arabic_quran_news_model\n",
        "\n",
        "cur_params={}\n",
        "cur_params[\"n_chars\"]=4\n",
        "cur_params[\"wv_model_path\"]=wv_fpath\n",
        "\n",
        "def process_features_labels(feature_label_item, labels0=[], params0={}, cur_rnn=None):\n",
        "  feature_list=[]\n",
        "  labels_list=[]\n",
        "  for item_i,cur_item in enumerate(feature_label_item):\n",
        "    word0,pos0=cur_item\n",
        "    features0=extract_word_features(word0,params0)\n",
        "    #if len(additional_features)>0: features0.extend(additional_features[item_i]) \n",
        "    labels_one_hot0=one_hot_encoder(pos0,labels0)\n",
        "    feature_list.append(features0)\n",
        "    labels_list.append(labels_one_hot0)\n",
        "  input_tensor=torch.tensor(feature_list,dtype=torch.float32)\n",
        "  if cur_rnn!=None:\n",
        "    rnn_out=cur_rnn(input_tensor)\n",
        "    new_feature_list=[]\n",
        "    for ft_i, ft_item in enumerate(feature_list):\n",
        "      cur_rnn_out_item=rnn_out[ft_i]\n",
        "      combined_ft_rnn_out=ft_item+list(cur_rnn_out_item)\n",
        "      new_feature_list.append(combined_ft_rnn_out)\n",
        "    input_tensor=torch.tensor(new_feature_list,dtype=torch.float32)\n",
        "\n",
        "  \n",
        "  output_tensor=torch.tensor(labels_list,dtype=torch.float32)\n",
        "  return input_tensor, output_tensor\n",
        "\n",
        "def eval_func(rnn_out0,actual_out0,possible_labels0):\n",
        "  rnn_flat_out0=rnn_out0.ravel()\n",
        "  predicted0=out2labels(rnn_flat_out0,possible_labels0)\n",
        "  outcome=[]\n",
        "  for actual0, pr in zip(actual_out0,predicted0) :\n",
        "    pr=[[v[0],round(v[1].item(),4)] for v in pr]\n",
        "    if actual0==\"\": continue\n",
        "    outcome.append((actual0,pr[0][0]))\n",
        "  return outcome\n",
        "\n",
        "def log_something(text0,fpath0):\n",
        "  fopen0=open(fpath0,\"a\")\n",
        "  fopen0.write(text0+\"\\n\")\n",
        "  fopen0.close()\n",
        "\n",
        "cur_data_item=train_data[0]\n",
        "input_tensor1,output_tensot1=process_features_labels(cur_data_item,pos_tags,cur_params)\n",
        "n_input=input_tensor1.shape[1]\n",
        "n_output=output_tensot1.shape[1]\n",
        "print(input_tensor1.shape)\n",
        "print(output_tensot1.shape)\n",
        "print(\"n_input\",n_input)\n",
        "print(\"n_output\",n_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bloMZAm4vd__"
      },
      "source": [
        "### 2- بدء التدريب الفعلي"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62WSmWucntvQ",
        "outputId": "fc8f27dc-19ed-412d-ca14-8d16a3cfd350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training - epoch 0 - 0 / 993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training - epoch 0 - 500 / 993\n",
            "testing - epoch 0 - 0 / 332\n",
            "Epoch: 0 - train loss: 0.0303 - test loss: 0.0193 - train eval: 0.569 - test eval: 0.6847\n",
            "training - epoch 1 - 0 / 993\n",
            "training - epoch 1 - 500 / 993\n",
            "testing - epoch 1 - 0 / 332\n",
            "Epoch: 1 - train loss: 0.018 - test loss: 0.0142 - train eval: 0.7128 - test eval: 0.7427\n",
            "training - epoch 2 - 0 / 993\n",
            "training - epoch 2 - 500 / 993\n",
            "testing - epoch 2 - 0 / 332\n",
            "Epoch: 2 - train loss: 0.0133 - test loss: 0.0126 - train eval: 0.7712 - test eval: 0.7639\n",
            "training - epoch 3 - 0 / 993\n",
            "training - epoch 3 - 500 / 993\n",
            "testing - epoch 3 - 0 / 332\n",
            "Epoch: 3 - train loss: 0.0101 - test loss: 0.0117 - train eval: 0.8057 - test eval: 0.7714\n",
            "training - epoch 4 - 0 / 993\n",
            "training - epoch 4 - 500 / 993\n",
            "testing - epoch 4 - 0 / 332\n",
            "Epoch: 4 - train loss: 0.0077 - test loss: 0.0109 - train eval: 0.8337 - test eval: 0.78\n",
            "training - epoch 5 - 0 / 993\n",
            "training - epoch 5 - 500 / 993\n",
            "testing - epoch 5 - 0 / 332\n",
            "Epoch: 5 - train loss: 0.0061 - test loss: 0.0108 - train eval: 0.851 - test eval: 0.7759\n",
            "training - epoch 6 - 0 / 993\n",
            "training - epoch 6 - 500 / 993\n",
            "testing - epoch 6 - 0 / 332\n",
            "Epoch: 6 - train loss: 0.005 - test loss: 0.0102 - train eval: 0.8625 - test eval: 0.7817\n",
            "training - epoch 7 - 0 / 993\n",
            "training - epoch 7 - 500 / 993\n",
            "testing - epoch 7 - 0 / 332\n",
            "Epoch: 7 - train loss: 0.0043 - test loss: 0.0102 - train eval: 0.8723 - test eval: 0.7897\n",
            "training - epoch 8 - 0 / 993\n",
            "training - epoch 8 - 500 / 993\n",
            "testing - epoch 8 - 0 / 332\n",
            "Epoch: 8 - train loss: 0.0041 - test loss: 0.0116 - train eval: 0.8776 - test eval: 0.7755\n",
            "training - epoch 9 - 0 / 993\n",
            "training - epoch 9 - 500 / 993\n",
            "testing - epoch 9 - 0 / 332\n",
            "Epoch: 9 - train loss: 0.0031 - test loss: 0.0103 - train eval: 0.887 - test eval: 0.7822\n",
            "training - epoch 10 - 0 / 993\n",
            "training - epoch 10 - 500 / 993\n",
            "testing - epoch 10 - 0 / 332\n",
            "Epoch: 10 - train loss: 0.0024 - test loss: 0.0107 - train eval: 0.8915 - test eval: 0.7832\n",
            "training - epoch 11 - 0 / 993\n"
          ]
        }
      ],
      "source": [
        "# n_input=426 \n",
        "# n_output=23\n",
        "torch.seed()\n",
        "exp_name=\"exp4-external\"\n",
        "cur_exp_labels=pos_tags\n",
        "\n",
        "n_hidden =512 #512\n",
        "n_layers=2\n",
        "LR=0.00001\n",
        "matching_in_out=True\n",
        "n_epochs=200\n",
        "loss_func = nn.MSELoss()\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers,matching_in_out=True).to(device)\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR) \n",
        "experiment_dir=\"experiments\"\n",
        "full_exp_dir_path=os.path.join(experiment_dir,exp_name)\n",
        "if not os.path.exists(full_exp_dir_path): os.makedirs(full_exp_dir_path)\n",
        "\n",
        "log_fpath=os.path.join(full_exp_dir_path,\"log.txt\")\n",
        "eval_log_fpath=os.path.join(full_exp_dir_path,\"eval-log.txt\")\n",
        "\n",
        "log_something(str(rnn),log_fpath)\n",
        "log_something(str(cur_params),log_fpath)\n",
        "output_log_headers=[\"Epoch\", \"train loss\",\"test loss\",\"train accuracy\", \"test accuracy\"]\n",
        "log_something(\"\\t\".join(output_log_headers) ,log_fpath)\n",
        "\n",
        "\n",
        "avg_train_loss_list = []\n",
        "avg_test_loss_list = []\n",
        "epochs_list = []\n",
        "for epoch in range(n_epochs):\n",
        "  epoch_train_loss,epoch_test_loss=0,0\n",
        "  train_eval_items,test_eval_items=[],[]\n",
        "  model_name=\"model-%s.model\"%epoch\n",
        "  tmp_path=os.path.join(full_exp_dir_path,model_name)\n",
        "  if os.path.exists(tmp_path):\n",
        "    print(\"found model:\",tmp_path)\n",
        "    checkpoint = torch.load(tmp_path)\n",
        "    rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    rnn.train()\n",
        "    continue\n",
        "\n",
        "  for i0,item in enumerate(train_data):\n",
        "    if i0%500==0: print(\"training - epoch\", epoch, \"-\",  i0,\"/\",len(train_data))\n",
        "    item_words0=[v[0] for v in item]\n",
        "    item_labels0=[v[1] for v in item]\n",
        "    in0,out0=process_features_labels(item, pos_tags,cur_params)\n",
        "    rnn_output=rnn(in0)\n",
        "    cur_loss=loss_func(rnn_output,out0)\n",
        "    cur_loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_train_loss+=cur_loss.item()\n",
        "    cur_train_eval_out=eval_func(rnn_output,item_labels0,pos_tags)\n",
        "    train_eval_items.extend(cur_train_eval_out)\n",
        "\n",
        "    \n",
        "  for i0,item in enumerate(test_data) :\n",
        "    if i0%500==0: print(\"testing - epoch\", epoch, \"-\",  i0,\"/\",len(test_data))\n",
        "    item_words0=[v[0] for v in item]\n",
        "    item_labels0=[v[1] for v in item]\n",
        "    in0,out0=process_features_labels(item, pos_tags,cur_params)\n",
        "    rnn_output=rnn(in0)\n",
        "    cur_loss=loss_func(rnn_output,out0)\n",
        "    cur_test_eval_out=eval_func(rnn_output,item_labels0,pos_tags)\n",
        "    test_eval_items.extend(cur_test_eval_out)\n",
        "\n",
        "    # cur_loss.backward()\n",
        "    # optimizer.step()\n",
        "    epoch_test_loss+=cur_loss.item()\n",
        "  avg_train_loss=epoch_train_loss/len(train_data)\n",
        "  avg_test_loss=epoch_test_loss/len(test_data)\n",
        "  correct_train_eval_items=[v for v in train_eval_items if v[0]==v[1]]\n",
        "  correct_test_eval_items=[v for v in test_eval_items if v[0]==v[1]]\n",
        "  train_eval=len(correct_train_eval_items)/len(train_eval_items)\n",
        "  test_eval=len(correct_test_eval_items)/len(test_eval_items)\n",
        "\n",
        "  # avg_train_loss_list.append(avg_train_loss)\n",
        "  # avg_test_loss_list.append(avg_test_loss)\n",
        "  # epochs_list.append(epoch)\n",
        "  log_line0='Epoch: %s - train loss: %s - test loss: %s - train eval: %s - test eval: %s'%(epoch,round(avg_train_loss,4), round(avg_test_loss,4), round(train_eval,4),round(test_eval,4))\n",
        "  print(log_line0)\n",
        "  log_something(log_line0,log_fpath)\n",
        "  output_vals=[epoch,round(avg_train_loss,4), round(avg_test_loss,4), round(train_eval,4),round(test_eval,4)]\n",
        "  output_vals=[str(v) for v in output_vals]\n",
        "\n",
        "  log_something(\"\\t\".join(output_vals) ,eval_log_fpath)\n",
        "\n",
        "\n",
        "  #print(epoch, \" train loss\",round(avg_train_loss,4), \"test loss\", round(avg_test_loss,4), \"train_eval\", round(train_eval,4), \"test_eval\",round(test_eval,4))\n",
        "  #print(\"-------\")\n",
        "  cur_checkpoint={\n",
        "                  'epoch': epoch,\n",
        "                  'n_input': n_input,\n",
        "                  'n_hidden': n_hidden,\n",
        "                  'n_layers': n_layers,\n",
        "                  'n_output': n_output,\n",
        "                  'LR': LR,\n",
        "                  'model_state_dict': rnn.state_dict(),\n",
        "                  'matching_in_out':matching_in_out,\n",
        "                  'train_loss': avg_train_loss,\n",
        "                  'test_loss': avg_test_loss,\n",
        "                  'labels': pos_tags,\n",
        "                  'feature_extraction_parameters': cur_params\n",
        "                  }\n",
        "\n",
        "  torch.save(cur_checkpoint, tmp_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag1Ksm_mu9xd"
      },
      "source": [
        "## سادسا - استخدام النماذج التي جرى تدريبها على مجموعات بيانات الاختبار"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- تحديد كفاءة النموذج على بيانات الاختبار عموما"
      ],
      "metadata": {
        "id": "0BFI85XAbHEW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D6-ykY9yKiu",
        "outputId": "29cd4bf7-09fb-47f7-cd58-dec763d505bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tNoun\tAdjective\tProper Noun\tVerb\tPreposition\tDemonstrative\tComplementizer\tTemporal\tPronoun\tNegation\tModal particles\tConjunction particles\tExceptive particles\tQuestion words\tNumber\tPunctuation\tForeign\tOther\n",
            "Noun\t3170\t42\t32\t63\t3\t0\t1\t3\t0\t2\t0\t0\t0\t0\t0\t0\t1\t6\n",
            "Adjective\t189\t284\t9\t4\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "Proper Noun\t100\t11\t303\t3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
            "Verb\t162\t3\t3\t681\t2\t0\t0\t0\t0\t0\t3\t0\t0\t0\t0\t0\t0\t0\n",
            "Preposition\t28\t0\t0\t6\t587\t0\t2\t0\t0\t0\t2\t0\t0\t0\t0\t2\t6\t16\n",
            "Demonstrative\t2\t0\t0\t0\t1\t18\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "Complementizer\t4\t0\t0\t0\t4\t2\t74\t0\t0\t6\t1\t0\t0\t0\t0\t0\t0\t4\n",
            "Temporal\t8\t1\t0\t0\t1\t0\t0\t9\t0\t0\t1\t0\t0\t0\t0\t0\t0\t4\n",
            "Pronoun\t2\t0\t0\t0\t1\t0\t0\t0\t30\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "Negation\t0\t0\t0\t0\t0\t0\t1\t0\t0\t77\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "Modal particles\t5\t0\t0\t2\t0\t0\t0\t0\t0\t0\t39\t3\t0\t0\t0\t0\t0\t25\n",
            "Conjunction particles\t4\t0\t0\t2\t1\t0\t1\t1\t0\t0\t8\t17\t2\t0\t0\t0\t0\t32\n",
            "Exceptive particles\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t13\t0\t0\t0\t0\t0\n",
            "Question words\t2\t0\t0\t2\t9\t1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t4\n",
            "Number\t1\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "Punctuation\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t406\t0\t0\n",
            "Foreign\t5\t1\t1\t3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t25\t0\n",
            "Other\t11\t0\t0\t2\t1\t0\t0\t0\t0\t7\t4\t3\t2\t0\t0\t0\t0\t43\n",
            "Prediction accuracy: 79.0\n"
          ]
        }
      ],
      "source": [
        "model_number=7\n",
        "exp_name=\"exp4-external\"\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "\n",
        "wv_dict={} #global variable - we will need to improve the implementation here\n",
        "wv_dict[wv_fpath]=arabic_quran_news_model\n",
        "\n",
        "#إعادة تحديد الشبكة من نقطة التحقق\n",
        "experiment_dir=\"experiments\"\n",
        "model_fname=\"model-%s.model\"%model_number\n",
        "PATH=os.path.join(experiment_dir,exp_name,model_fname)\n",
        "checkpoint = torch.load(PATH)\n",
        "model_feature_extraction_params=checkpoint[\"feature_extraction_parameters\"]\n",
        "model_labels=checkpoint[\"labels\"]\n",
        "\n",
        "rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "\n",
        "rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "rnn.eval()\n",
        "\n",
        "test_eval_items=[]\n",
        "for item in test_data:\n",
        "  item_words0=[v[0] for v in item]\n",
        "  item_labels0=[v[1] for v in item]\n",
        "  in0,out0=process_features_labels(item, model_labels, model_feature_extraction_params)\n",
        "  rnn_output=rnn(in0)\n",
        "  cur_loss=loss_func(rnn_output,out0)\n",
        "  cur_test_eval_out=eval_func(rnn_output,item_labels0,model_labels)\n",
        "  test_eval_items.extend(cur_test_eval_out)\n",
        "\n",
        "from collections import Counter\n",
        "counter_obj=Counter(test_eval_items)\n",
        "\n",
        "header_items=[\"\"]+model_labels\n",
        "print(\"\\t\".join(header_items) )\n",
        "for lb0 in model_labels:\n",
        "  row_items=[lb0]\n",
        "  for lb1 in model_labels:\n",
        "    cur_count_val=counter_obj.get((lb0,lb1),0)\n",
        "    row_items.append(str(cur_count_val))\n",
        "  print(\"\\t\".join(row_items) )\n",
        "\n",
        "test_eval_items_correct=[v for v in test_eval_items if v[0]==v[1]]\n",
        "correctness_ratio=len(test_eval_items_correct)/len(test_eval_items)\n",
        "correctness_percent=round(correctness_ratio*100,1)\n",
        "print(\"Prediction accuracy: %s\"%correctness_percent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2- تحديد دقة النموذج على النص القرآني"
      ],
      "metadata": {
        "id": "3soZBf1GbO-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval_items=[]\n",
        "for item in quran_test_data:\n",
        "  item_words0=[v[0] for v in item]\n",
        "  item_labels0=[v[1] for v in item]\n",
        "  in0,out0=process_features_labels(item, model_labels, model_feature_extraction_params)\n",
        "  rnn_output=rnn(in0)\n",
        "  cur_loss=loss_func(rnn_output,out0)\n",
        "  cur_test_eval_out=eval_func(rnn_output,item_labels0,model_labels)\n",
        "  test_eval_items.extend(cur_test_eval_out)\n",
        "\n",
        "test_eval_items_correct=[v for v in test_eval_items if v[0]==v[1]]\n",
        "correctness_ratio=len(test_eval_items_correct)/len(test_eval_items)\n",
        "correctness_percent=round(correctness_ratio*100,1)\n",
        "print(\"Quran Prediction accuracy: %s\"%correctness_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFII6tRsY-TL",
        "outputId": "b9025491-f658-4020-90ba-d8f7b5e393f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quran Prediction accuracy: 81.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3- تحديد دقة النموذج على النص الإخباري"
      ],
      "metadata": {
        "id": "0tf5XL65bUVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval_items=[]\n",
        "for item in news_test_data:\n",
        "  item_words0=[v[0] for v in item]\n",
        "  item_labels0=[v[1] for v in item]\n",
        "  in0,out0=process_features_labels(item, model_labels, model_feature_extraction_params)\n",
        "  rnn_output=rnn(in0)\n",
        "  cur_loss=loss_func(rnn_output,out0)\n",
        "  cur_test_eval_out=eval_func(rnn_output,item_labels0,model_labels)\n",
        "  test_eval_items.extend(cur_test_eval_out)\n",
        "\n",
        "test_eval_items_correct=[v for v in test_eval_items if v[0]==v[1]]\n",
        "correctness_ratio=len(test_eval_items_correct)/len(test_eval_items)\n",
        "correctness_percent=round(correctness_ratio*100,1)\n",
        "print(\"News Prediction accuracy: %s\"%correctness_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXxYnsieZZ8b",
        "outputId": "171a943d-fdd0-455d-c694-54d41b407f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News Prediction accuracy: 78.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval_items=[]\n",
        "for item in external_test_data:\n",
        "  item_words0=[v[0] for v in item]\n",
        "  item_labels0=[v[1] for v in item]\n",
        "  in0,out0=process_features_labels(item, model_labels, model_feature_extraction_params)\n",
        "  rnn_output=rnn(in0)\n",
        "  cur_loss=loss_func(rnn_output,out0)\n",
        "  cur_test_eval_out=eval_func(rnn_output,item_labels0,model_labels)\n",
        "  test_eval_items.extend(cur_test_eval_out)\n",
        "\n",
        "test_eval_items_correct=[v for v in test_eval_items if v[0]==v[1]]\n",
        "correctness_ratio=len(test_eval_items_correct)/len(test_eval_items)\n",
        "correctness_percent=round(correctness_ratio*100,1)\n",
        "print(\"External Prediction accuracy: %s\"%correctness_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "zgjjl3j2ZiH-",
        "outputId": "9bd82567-7ef3-4ae8-aa7b-ffeb421812fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f23faaf2cb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mitem_labels0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0min0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_feature_extraction_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mrnn_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mcur_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mcur_test_eval_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_labels0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-9f8fcd9f8efc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feature_list)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mfeature_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#### <<<<<<<<<<<<<<<<<\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching_in_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m       \u001b[0moutput_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_sigmoid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 762\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIfgy9KE4PLh"
      },
      "outputs": [],
      "source": [
        "#أختبار النماذج على جمل جديدة\n",
        "\n",
        "sent=\"هذا أخي له نعجة\"\n",
        "#sent=\"هذه النعجة فقال أكفلنيها\"\n",
        "sent=\"فقال اذهبا بآيتي\"\n",
        "words=sent.split()\n",
        "word_features=[extract_word_features(v,cur_params) for v in words]\n",
        "feature_tensor=torch.tensor(word_features, dtype=torch.float32) \n",
        "\n",
        "\n",
        "rnn_output=rnn(feature_tensor)\n",
        "#print(rnn_output.shape)\n",
        "rnn_flat_out=rnn_output.ravel()\n",
        "predicted=out2labels(rnn_flat_out,pos_tags)\n",
        "for word, pr in zip(words,predicted) :\n",
        "  pr=[[v[0],round(v[1].item(),4)] for v in pr]\n",
        "  print(word,pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPcJsW_dmzGe"
      },
      "outputs": [],
      "source": [
        "# import joblib\n",
        "from joblib import dump\n",
        "\n",
        "# dump the pipeline model\n",
        "dump(pipeline, filename=\"text_classification.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptl4UQxrmZJi"
      },
      "source": [
        "##سابعا - التدريب على الأطر"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- تجهيز بيانات أطر الأفعال للتدريب عليها"
      ],
      "metadata": {
        "id": "OCYd340RN2rR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yROg_yCMl-M1",
        "outputId": "fe9b3440-5f4a-4ca9-a4bb-3cca2cce867d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quran_frame_train 113\n",
            "quran_frame_test 39\n",
            "torch.Size([50, 886])\n",
            "torch.Size([50, 15])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "#loading frame list\n",
        "model_number=7\n",
        "exp_name=\"exp4-external\"\n",
        "from gensim.models import Word2Vec\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "wv_dict={} #global variable - we will need to improve the implementation here\n",
        "wv_dict[wv_fpath]=arabic_quran_news_model\n",
        "#إعادة تحديد الشبكة من نقطة التحقق\n",
        "experiment_dir=\"experiments\"\n",
        "model_fname=\"model-%s.model\"%model_number\n",
        "PATH=os.path.join(experiment_dir,exp_name,model_fname)\n",
        "checkpoint = torch.load(PATH)\n",
        "model_feature_extraction_params=checkpoint[\"feature_extraction_parameters\"]\n",
        "model_labels=checkpoint[\"labels\"]\n",
        "pos_rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "pos_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "pos_rnn.eval()\n",
        "\n",
        "\n",
        "\n",
        "annotated_dir=\"annotated\"\n",
        "annotated_meta_dir=os.path.join(annotated_dir,\"meta\")\n",
        "annotation_frames_fname=\"quran-annotation-frames.txt\"\n",
        "frame_fpath=os.path.join(annotated_meta_dir,annotation_frames_fname)\n",
        "frame_list=read_json(frame_fpath)\n",
        "\n",
        "#loading word embeddings\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "wv_dict={} #global variable - we will need to improve the implementation here\n",
        "wv_dict[wv_fpath]=arabic_quran_news_model\n",
        "\n",
        "#defining feature extraction parameters\n",
        "cur_params={}\n",
        "cur_params[\"n_chars\"]=4\n",
        "cur_params[\"wv_model_path\"]=wv_fpath\n",
        "\n",
        "news_frame_data= read_group_data(news_annotation_fpath,\"word\",\"Frame\",\"sentence-id\") \n",
        "quran_frame_data= read_group_data(quran_annotation_fpath,\"word\",\"Frame\",\"sura-aya\")\n",
        "quran_new_frame_data=[]\n",
        "for item in quran_frame_data:\n",
        "  frame_test=[v for v in item if v[1]!=\"\"]\n",
        "  if not frame_test: continue\n",
        "  quran_new_frame_data.append(item)\n",
        "\n",
        "news_new_frame_data=[]\n",
        "for item in news_frame_data:\n",
        "  frame_test=[v for v in item if v[1]!=\"\"]\n",
        "  if not frame_test: continue\n",
        "  news_new_frame_data.append(item)\n",
        "# quran_train_data,quran_test_data=split_train_test(quran_data)\n",
        "# news_train_data,news_test_data=split_train_test(news_data)\n",
        "# train_data=quran_train_data+news_train_data\n",
        "# test_data=quran_test_data+news_test_data\n",
        "\n",
        "# random.shuffle(train_data)\n",
        "# random.shuffle(test_data)\n",
        "\n",
        "\n",
        "quran_frame_train,quran_frame_test=split_train_test(quran_new_frame_data)\n",
        "news_frame_train,news_frame_test=split_train_test(news_new_frame_data)\n",
        "\n",
        "\n",
        "\n",
        "frame_train_data=quran_frame_train+news_frame_train\n",
        "frame_test_data=quran_frame_test+news_frame_test\n",
        "\n",
        "print(\"frame_train\",len(frame_train_data))\n",
        "print(\"frame_test\",len(frame_test_data))\n",
        "\n",
        "random.shuffle(frame_train_data)\n",
        "random.shuffle(frame_test_data)\n",
        "\n",
        "cur_data_item=frame_train_data[0]\n",
        "\n",
        "#pos_model_output=rnn()\n",
        "\n",
        "input_tensor1,output_tensot1=process_features_labels(cur_data_item,frame_list,cur_params, pos_rnn)\n",
        "n_input=input_tensor1.shape[1]\n",
        "n_output=output_tensot1.shape[1]\n",
        "print(input_tensor1.shape)\n",
        "print(output_tensot1.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-  البدء الفعلي لتدريب الشبكة على بيانات الأطر"
      ],
      "metadata": {
        "id": "_jn2wAxwN9L1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w6g-BJArv5tG",
        "outputId": "ef0f1c04-cb01-4704-d305-38df0a4b902f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 - train loss: 0.0074 - test loss: 0.0042 - train eval: 0.0663 - test eval: 0.0067\n",
            "Epoch: 1 - train loss: 0.0038 - test loss: 0.0031 - train eval: 0.0186 - test eval: 0.0\n",
            "Epoch: 2 - train loss: 0.0029 - test loss: 0.0026 - train eval: 0.0207 - test eval: 0.0\n",
            "Epoch: 3 - train loss: 0.0025 - test loss: 0.0025 - train eval: 0.0311 - test eval: 0.0\n",
            "Epoch: 4 - train loss: 0.0023 - test loss: 0.0023 - train eval: 0.0642 - test eval: 0.0134\n",
            "Epoch: 5 - train loss: 0.0022 - test loss: 0.0024 - train eval: 0.1781 - test eval: 0.0671\n",
            "Epoch: 6 - train loss: 0.002 - test loss: 0.0023 - train eval: 0.3168 - test eval: 0.0872\n",
            "Epoch: 7 - train loss: 0.0019 - test loss: 0.0023 - train eval: 0.3271 - test eval: 0.094\n",
            "Epoch: 8 - train loss: 0.0018 - test loss: 0.0023 - train eval: 0.3706 - test eval: 0.094\n",
            "Epoch: 9 - train loss: 0.0017 - test loss: 0.0023 - train eval: 0.3872 - test eval: 0.1208\n",
            "Epoch: 10 - train loss: 0.0017 - test loss: 0.0024 - train eval: 0.4265 - test eval: 0.1074\n",
            "Epoch: 11 - train loss: 0.0017 - test loss: 0.0024 - train eval: 0.441 - test eval: 0.1007\n",
            "Epoch: 12 - train loss: 0.0016 - test loss: 0.0025 - train eval: 0.4865 - test eval: 0.1007\n",
            "Epoch: 13 - train loss: 0.0016 - test loss: 0.0026 - train eval: 0.5342 - test eval: 0.1141\n",
            "Epoch: 14 - train loss: 0.0015 - test loss: 0.0026 - train eval: 0.5901 - test eval: 0.1275\n",
            "Epoch: 15 - train loss: 0.0015 - test loss: 0.0028 - train eval: 0.6315 - test eval: 0.1141\n",
            "Epoch: 16 - train loss: 0.0015 - test loss: 0.0029 - train eval: 0.6294 - test eval: 0.1074\n",
            "Epoch: 17 - train loss: 0.0014 - test loss: 0.003 - train eval: 0.6563 - test eval: 0.1141\n",
            "Epoch: 18 - train loss: 0.0014 - test loss: 0.0032 - train eval: 0.6667 - test eval: 0.1208\n",
            "Epoch: 19 - train loss: 0.0013 - test loss: 0.0031 - train eval: 0.6915 - test eval: 0.1141\n",
            "Epoch: 20 - train loss: 0.0013 - test loss: 0.0033 - train eval: 0.6998 - test eval: 0.1208\n",
            "Epoch: 21 - train loss: 0.0014 - test loss: 0.0033 - train eval: 0.7081 - test eval: 0.1208\n",
            "Epoch: 22 - train loss: 0.0013 - test loss: 0.0034 - train eval: 0.7019 - test eval: 0.1275\n",
            "Epoch: 23 - train loss: 0.0013 - test loss: 0.0035 - train eval: 0.7288 - test eval: 0.1275\n",
            "Epoch: 24 - train loss: 0.0013 - test loss: 0.0035 - train eval: 0.7371 - test eval: 0.1208\n",
            "Epoch: 25 - train loss: 0.0012 - test loss: 0.0036 - train eval: 0.7391 - test eval: 0.1141\n",
            "Epoch: 26 - train loss: 0.0012 - test loss: 0.0037 - train eval: 0.7453 - test eval: 0.1208\n",
            "Epoch: 27 - train loss: 0.0012 - test loss: 0.0038 - train eval: 0.7598 - test eval: 0.1208\n",
            "Epoch: 28 - train loss: 0.0012 - test loss: 0.0038 - train eval: 0.766 - test eval: 0.1477\n",
            "Epoch: 29 - train loss: 0.0011 - test loss: 0.0038 - train eval: 0.764 - test eval: 0.1409\n",
            "Epoch: 30 - train loss: 0.0012 - test loss: 0.0039 - train eval: 0.7536 - test eval: 0.1342\n",
            "Epoch: 31 - train loss: 0.0012 - test loss: 0.0039 - train eval: 0.7453 - test eval: 0.1275\n",
            "Epoch: 32 - train loss: 0.0012 - test loss: 0.0038 - train eval: 0.7619 - test eval: 0.1342\n",
            "Epoch: 33 - train loss: 0.0011 - test loss: 0.0038 - train eval: 0.766 - test eval: 0.1342\n",
            "Epoch: 34 - train loss: 0.0012 - test loss: 0.004 - train eval: 0.7702 - test eval: 0.1477\n",
            "Epoch: 35 - train loss: 0.0012 - test loss: 0.004 - train eval: 0.7764 - test eval: 0.1477\n",
            "Epoch: 36 - train loss: 0.0011 - test loss: 0.004 - train eval: 0.7764 - test eval: 0.1409\n",
            "Epoch: 37 - train loss: 0.0012 - test loss: 0.0042 - train eval: 0.7785 - test eval: 0.1409\n",
            "Epoch: 38 - train loss: 0.0012 - test loss: 0.0042 - train eval: 0.7785 - test eval: 0.1409\n",
            "Epoch: 39 - train loss: 0.0011 - test loss: 0.004 - train eval: 0.7826 - test eval: 0.1409\n",
            "Epoch: 40 - train loss: 0.0011 - test loss: 0.0041 - train eval: 0.7867 - test eval: 0.1409\n",
            "Epoch: 41 - train loss: 0.0012 - test loss: 0.0043 - train eval: 0.7888 - test eval: 0.1409\n",
            "Epoch: 42 - train loss: 0.0012 - test loss: 0.0043 - train eval: 0.7888 - test eval: 0.1342\n",
            "Epoch: 43 - train loss: 0.0011 - test loss: 0.0043 - train eval: 0.8012 - test eval: 0.1409\n",
            "Epoch: 44 - train loss: 0.0011 - test loss: 0.0043 - train eval: 0.8012 - test eval: 0.1409\n",
            "Epoch: 45 - train loss: 0.0012 - test loss: 0.0044 - train eval: 0.7888 - test eval: 0.1342\n",
            "Epoch: 46 - train loss: 0.0012 - test loss: 0.0044 - train eval: 0.7867 - test eval: 0.1342\n",
            "Epoch: 47 - train loss: 0.0011 - test loss: 0.0043 - train eval: 0.7888 - test eval: 0.1342\n",
            "Epoch: 48 - train loss: 0.0011 - test loss: 0.0044 - train eval: 0.7971 - test eval: 0.1342\n",
            "Epoch: 49 - train loss: 0.0012 - test loss: 0.0046 - train eval: 0.795 - test eval: 0.1342\n",
            "Epoch: 50 - train loss: 0.0012 - test loss: 0.0046 - train eval: 0.8033 - test eval: 0.1342\n",
            "Epoch: 51 - train loss: 0.0011 - test loss: 0.0046 - train eval: 0.8033 - test eval: 0.1342\n",
            "Epoch: 52 - train loss: 0.0011 - test loss: 0.0047 - train eval: 0.795 - test eval: 0.1342\n",
            "Epoch: 53 - train loss: 0.0012 - test loss: 0.0047 - train eval: 0.793 - test eval: 0.1342\n",
            "Epoch: 54 - train loss: 0.0012 - test loss: 0.0047 - train eval: 0.8033 - test eval: 0.1342\n",
            "Epoch: 55 - train loss: 0.0011 - test loss: 0.0046 - train eval: 0.8033 - test eval: 0.1342\n",
            "Epoch: 56 - train loss: 0.0011 - test loss: 0.0047 - train eval: 0.8012 - test eval: 0.1409\n",
            "Epoch: 57 - train loss: 0.0012 - test loss: 0.0048 - train eval: 0.7971 - test eval: 0.1342\n",
            "Epoch: 58 - train loss: 0.0012 - test loss: 0.0048 - train eval: 0.7992 - test eval: 0.1275\n",
            "Epoch: 59 - train loss: 0.0011 - test loss: 0.0047 - train eval: 0.795 - test eval: 0.1275\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-34f3a229a6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mitem_words0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mitem_labels0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0min0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_exp_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_rnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mrnn_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcur_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-039fb0719ac0>\u001b[0m in \u001b[0;36mprocess_features_labels\u001b[0;34m(feature_label_item, labels0, params0, cur_rnn)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlabels_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_one_hot0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcur_rnn\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrnn_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#بدء التدريب على الأطر\n",
        "torch.seed()\n",
        "exp_name=\"exp9-frames\"\n",
        "cur_exp_labels=frame_list\n",
        "n_hidden = 64\n",
        "n_layers=1\n",
        "LR=0.0001\n",
        "matching_in_out=True\n",
        "n_epochs=100\n",
        "loss_func = nn.MSELoss()\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers,matching_in_out=True).to(device)\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR) \n",
        "experiment_dir=\"experiments\"\n",
        "full_exp_dir_path=os.path.join(experiment_dir,exp_name)\n",
        "if not os.path.exists(full_exp_dir_path): os.makedirs(full_exp_dir_path)\n",
        "\n",
        "log_fpath=os.path.join(full_exp_dir_path,\"log.txt\")\n",
        "eval_log_fpath=os.path.join(full_exp_dir_path,\"eval-log.txt\")\n",
        "\n",
        "log_something(str(rnn),log_fpath)\n",
        "log_something(str(cur_params),log_fpath)\n",
        "output_log_headers=[\"Epoch\", \"train loss\",\"test loss\",\"train accuracy\", \"test accuracy\"]\n",
        "log_something(\"\\t\".join(output_log_headers) ,log_fpath)\n",
        "\n",
        "\n",
        "avg_train_loss_list = []\n",
        "avg_test_loss_list = []\n",
        "epochs_list = []\n",
        "for epoch in range(n_epochs):\n",
        "  epoch_train_loss,epoch_test_loss=0,0\n",
        "  train_eval_items,test_eval_items=[],[]\n",
        "  for item in frame_train_data:\n",
        "    item_words0=[v[0] for v in item]\n",
        "    item_labels0=[v[1] for v in item]\n",
        "    in0,out0=process_features_labels(item, cur_exp_labels,cur_params,pos_rnn)\n",
        "    rnn_output=rnn(in0)\n",
        "    cur_loss=loss_func(rnn_output,out0)\n",
        "    cur_loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_train_loss+=cur_loss.item()\n",
        "    cur_train_eval_out=eval_func(rnn_output,item_labels0,cur_exp_labels)\n",
        "    train_eval_items.extend(cur_train_eval_out)\n",
        "\n",
        "    \n",
        "  for item in frame_test_data:\n",
        "    item_words0=[v[0] for v in item]\n",
        "    item_labels0=[v[1] for v in item]\n",
        "    in0,out0=process_features_labels(item, cur_exp_labels,cur_params,pos_rnn)\n",
        "    rnn_output=rnn(in0)\n",
        "    cur_loss=loss_func(rnn_output,out0)\n",
        "    cur_test_eval_out=eval_func(rnn_output,item_labels0,cur_exp_labels)\n",
        "    test_eval_items.extend(cur_test_eval_out)\n",
        "\n",
        "    # cur_loss.backward()\n",
        "    # optimizer.step()\n",
        "    epoch_test_loss+=cur_loss.item()\n",
        "  avg_train_loss=epoch_train_loss/len(train_data)\n",
        "  avg_test_loss=epoch_test_loss/len(test_data)\n",
        "  correct_train_eval_items=[v for v in train_eval_items if v[0]==v[1]]\n",
        "  correct_test_eval_items=[v for v in test_eval_items if v[0]==v[1]]\n",
        "  train_eval=len(correct_train_eval_items)/len(train_eval_items)\n",
        "  test_eval=len(correct_test_eval_items)/len(test_eval_items)\n",
        "\n",
        "  # avg_train_loss_list.append(avg_train_loss)\n",
        "  # avg_test_loss_list.append(avg_test_loss)\n",
        "  # epochs_list.append(epoch)\n",
        "  log_line0='Epoch: %s - train loss: %s - test loss: %s - train eval: %s - test eval: %s'%(epoch,round(avg_train_loss,4), round(avg_test_loss,4), round(train_eval,4),round(test_eval,4))\n",
        "  print(log_line0)\n",
        "  log_something(log_line0,log_fpath)\n",
        "  output_vals=[epoch,round(avg_train_loss,4), round(avg_test_loss,4), round(train_eval,4),round(test_eval,4)]\n",
        "  output_vals=[str(v) for v in output_vals]\n",
        "\n",
        "  log_something(\"\\t\".join(output_vals) ,eval_log_fpath)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #print(epoch, \" train loss\",round(avg_train_loss,4), \"test loss\", round(avg_test_loss,4), \"train_eval\", round(train_eval,4), \"test_eval\",round(test_eval,4))\n",
        "  #print(\"-------\")\n",
        "  cur_checkpoint={\n",
        "                  'epoch': epoch,\n",
        "                  'n_input': n_input,\n",
        "                  'n_hidden': n_hidden,\n",
        "                  'n_layers': n_layers,\n",
        "                  'n_output': n_output,\n",
        "                  'LR': LR,\n",
        "                  'model_state_dict': rnn.state_dict(),\n",
        "                  'matching_in_out':matching_in_out,\n",
        "                  'train_loss': avg_train_loss,\n",
        "                  'test_loss': avg_test_loss,\n",
        "                  'labels': cur_exp_labels,\n",
        "                  'feature_extraction_parameters': cur_params\n",
        "                  }\n",
        "  model_name=\"model-%s.model\"%epoch\n",
        "  tmp_path=os.path.join(full_exp_dir_path,model_name)\n",
        "  torch.save(cur_checkpoint, tmp_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-73hQvGDbM7",
        "outputId": "828bb994-bbbe-4ea7-9bdd-f54da22ee19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tV\tV + OBJ\tV + 2OBJ\tV + Prep + Obj\tV + OBJ + Prep + OBJ\tV + anna + V\tV + inna + Sent\tV + anna + Sent\tV + Prep + anna + Sent\tV + Sent\tV + Prep + OBJ + Prep + OBJ\tV + 3OBJ\tV - passive\tOther\t\n",
            "V\t12\t8\t0\t1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t15\n",
            "V + OBJ\t2\t6\t0\t4\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t16\n",
            "V + 2OBJ\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\n",
            "V + Prep + Obj\t5\t2\t0\t4\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t11\n",
            "V + OBJ + Prep + OBJ\t1\t3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t6\n",
            "V + anna + V\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\n",
            "V + inna + Sent\t1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "V + anna + Sent\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "V + Prep + anna + Sent\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "V + Sent\t3\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "V + Prep + OBJ + Prep + OBJ\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "V + 3OBJ\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "V - passive\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "Other\t12\t8\t0\t3\t0\t0\t0\t0\t0\t1\t0\t0\t0\t1\t14\n",
            "\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
            "Prediction accuracy: 15.4\n"
          ]
        }
      ],
      "source": [
        "#testing on frame data\n",
        "\n",
        "model_number=37\n",
        "exp_name=\"exp6-frames\"\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "\n",
        "wv_dict={} #global variable - we will need to improve the implementation here\n",
        "wv_dict[wv_fpath]=arabic_quran_news_model\n",
        "\n",
        "#إعادة تحديد الشبكة من نقطة التحقق\n",
        "experiment_dir=\"experiments\"\n",
        "model_fname=\"model-%s.model\"%model_number\n",
        "PATH=os.path.join(experiment_dir,exp_name,model_fname)\n",
        "checkpoint = torch.load(PATH)\n",
        "model_feature_extraction_params=checkpoint[\"feature_extraction_parameters\"]\n",
        "model_labels=checkpoint[\"labels\"]\n",
        "\n",
        "rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "\n",
        "rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "rnn.eval()\n",
        "\n",
        "\n",
        "\n",
        "pos_model_number=7\n",
        "pos_exp_name=\"exp4-external\"\n",
        "model_fname=\"model-%s.model\"%pos_model_number\n",
        "pos_PATH=os.path.join(experiment_dir,pos_exp_name,model_fname)\n",
        "checkpoint = torch.load(pos_PATH)\n",
        "#model_feature_extraction_params=checkpoint[\"feature_extraction_parameters\"]\n",
        "pos_model_labels=checkpoint[\"labels\"]\n",
        "pos_rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "pos_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "pos_rnn.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_eval_items=[]\n",
        "for item in frame_test_data:\n",
        "  item_words0=[v[0] for v in item]\n",
        "  item_labels0=[v[1] for v in item]\n",
        "  in0,out0=process_features_labels(item, model_labels, model_feature_extraction_params,pos_rnn)\n",
        "  rnn_output=rnn(in0)\n",
        "  cur_loss=loss_func(rnn_output,out0)\n",
        "  cur_test_eval_out=eval_func(rnn_output,item_labels0,model_labels)\n",
        "  test_eval_items.extend(cur_test_eval_out)\n",
        "\n",
        "from collections import Counter\n",
        "counter_obj=Counter(test_eval_items)\n",
        "\n",
        "\n",
        "\n",
        "header_items=[\"\"]+model_labels\n",
        "print(\"\\t\".join(header_items) )\n",
        "for lb0 in model_labels:\n",
        "  row_items=[lb0]\n",
        "  for lb1 in model_labels:\n",
        "    cur_count_val=counter_obj.get((lb0,lb1),0)\n",
        "    row_items.append(str(cur_count_val))\n",
        "  print(\"\\t\".join(row_items) )\n",
        "\n",
        "test_eval_items_correct=[v for v in test_eval_items if v[0]==v[1]]\n",
        "correctness_ratio=len(test_eval_items_correct)/len(test_eval_items)\n",
        "correctness_percent=round(correctness_ratio*100,1)\n",
        "print(\"Prediction accuracy: %s\"%correctness_percent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUGkD5e9L_YP"
      },
      "source": [
        "##ثامنا - اختبار التسلسل بالكامل على جملة جديدة \n",
        "استخدام أفضل النماذج على أي جملة للتأكد من أن النظام يعمل كما ينبغي"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5CQtpluva8P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f39f18f5-178a-43be-9b8e-68f27b6ee63f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  الكلمات أقسام الكلام     أطر الأفعال\n",
              "0     قال         Verb        V + Sent\n",
              "1     أنا      Pronoun                \n",
              "2     عبد  Proper Noun                \n",
              "3    الله  Proper Noun                \n",
              "4   آتاني         Verb  V + Prep + Obj\n",
              "5  الكتاب         Noun                \n",
              "6  وجعلني         Verb  V + Prep + Obj\n",
              "7    نبيا         Noun                "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83c748cc-3a6e-4bda-8ace-9d1dd09967c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>الكلمات</th>\n",
              "      <th>أقسام الكلام</th>\n",
              "      <th>أطر الأفعال</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>قال</td>\n",
              "      <td>Verb</td>\n",
              "      <td>V + Sent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>أنا</td>\n",
              "      <td>Pronoun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>عبد</td>\n",
              "      <td>Proper Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>الله</td>\n",
              "      <td>Proper Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>آتاني</td>\n",
              "      <td>Verb</td>\n",
              "      <td>V + Prep + Obj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>الكتاب</td>\n",
              "      <td>Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>وجعلني</td>\n",
              "      <td>Verb</td>\n",
              "      <td>V + Prep + Obj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>نبيا</td>\n",
              "      <td>Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83c748cc-3a6e-4bda-8ace-9d1dd09967c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83c748cc-3a6e-4bda-8ace-9d1dd09967c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83c748cc-3a6e-4bda-8ace-9d1dd09967c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# model_number=37\n",
        "# exp_name=\"exp6-frames\"\n",
        "model_number=35\n",
        "exp_name=\"exp9-frames\"\n",
        "\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "\n",
        "wv_dict={} #global variable - we will need to improve the implementation here\n",
        "wv_dict[wv_fpath]=arabic_quran_news_model\n",
        "\n",
        "#إعادة تحديد الشبكة من نقطة التحقق\n",
        "experiment_dir=\"experiments\"\n",
        "model_fname=\"model-%s.model\"%model_number\n",
        "PATH=os.path.join(experiment_dir,exp_name,model_fname)\n",
        "checkpoint = torch.load(PATH)\n",
        "model_feature_extraction_params=checkpoint[\"feature_extraction_parameters\"]\n",
        "frame_labels=checkpoint[\"labels\"]\n",
        "\n",
        "frame_rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "\n",
        "frame_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "frame_rnn.eval()\n",
        "\n",
        "\n",
        "\n",
        "pos_model_number=7\n",
        "pos_exp_name=\"exp4-external\"\n",
        "model_fname=\"model-%s.model\"%pos_model_number\n",
        "pos_PATH=os.path.join(experiment_dir,pos_exp_name,model_fname)\n",
        "checkpoint = torch.load(pos_PATH)\n",
        "#model_feature_extraction_params=checkpoint[\"feature_extraction_parameters\"]\n",
        "pos_model_labels=checkpoint[\"labels\"]\n",
        "pos_rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "pos_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "pos_rnn.eval()\n",
        "\n",
        "def predict_pos_frame(sent0,first_rnn0,second_rnn0,first_labels0,second_labels0,feature_extraction_parameters0):\n",
        "  words0=sent0.split()\n",
        "  raw_feature_list=[]\n",
        "  for w0 in words0:\n",
        "    cur_ft_list=extract_word_features(w0,feature_extraction_parameters0)\n",
        "    raw_feature_list.append(cur_ft_list)\n",
        "  input_tensor=torch.tensor(raw_feature_list,dtype=torch.float32)\n",
        "  pos_rnn_out=first_rnn0(input_tensor)\n",
        "  pos_predictions=out2labels(pos_rnn_out.ravel(),first_labels0)\n",
        "  top_pos_predictions=[]\n",
        "  for a in pos_predictions:\n",
        "    top_pos_predictions.append(a[0][0])\n",
        "  level2_feature_list=[]\n",
        "  for i0, ft0 in enumerate(raw_feature_list):\n",
        "    combined_features=ft0+list(pos_rnn_out[i0])\n",
        "    level2_feature_list.append(combined_features)\n",
        "  level2_input_tensor=torch.tensor(level2_feature_list,dtype=torch.float32)\n",
        "  frame_rnn_out=second_rnn0(level2_input_tensor)\n",
        "  frame_predictions=out2labels(frame_rnn_out.ravel(),second_labels0)\n",
        "  final_output=[]\n",
        "  for wd0,pos0, fp in zip(words0,top_pos_predictions,frame_predictions):\n",
        "    if pos0==\"Verb\": \n",
        "      fp=[v for v in fp if v[0]!=\"\"]\n",
        "      top_frame=fp[0][0]\n",
        "    else:\n",
        "      top_frame=\"\"\n",
        "    final_output.append((wd0,pos0, top_frame))\n",
        "    #print(wd0,pos0, top_frame)\n",
        "  return final_output\n",
        "\n",
        "\n",
        "#sentence=\"أعطني هذا الكتاب وقال ماذا يفعل هنا\"\n",
        "sentence=\"قال أنا عبد الله آتاني الكتاب وجعلني نبيا\"\n",
        "\n",
        "output=predict_pos_frame(sentence,pos_rnn,frame_rnn,pos_model_labels,frame_labels,model_feature_extraction_params)\n",
        "\n",
        "df = pd.DataFrame(output,columns =['الكلمات',\"أقسام الكلام\",\"أطر الأفعال\"])\n",
        "df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence=\"قال أنا عبد الله آتاني الكتاب وجعلني نبيا\"\n",
        "sentence=input(\"يرجى إدخال جملة لتحليلها\\n\") or sample_sentence\n",
        "output=predict_pos_frame(sentence,pos_rnn,frame_rnn,pos_model_labels,frame_labels,model_feature_extraction_params)\n",
        "df = pd.DataFrame(output,columns =['الكلمات',\"أقسام الكلام\",\"أطر الأفعال\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "-N_YKiKU1Mpd",
        "outputId": "d09044a8-cd5e-4bc1-fb9b-232a13ce43b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "يرجى إدخال جملة لتحليلها\n",
            "يرجى إدخال جملة لتحليلها\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    الكلمات أقسام الكلام     أطر الأفعال\n",
              "0      يرجى         Verb  V + Prep + Obj\n",
              "1     إدخال         Noun         V + OBJ\n",
              "2      جملة         Noun                \n",
              "3  لتحليلها         Noun                "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0a4abcb-9d00-44ca-816c-b6dd777fa5d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>الكلمات</th>\n",
              "      <th>أقسام الكلام</th>\n",
              "      <th>أطر الأفعال</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يرجى</td>\n",
              "      <td>Verb</td>\n",
              "      <td>V + Prep + Obj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>إدخال</td>\n",
              "      <td>Noun</td>\n",
              "      <td>V + OBJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>جملة</td>\n",
              "      <td>Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>لتحليلها</td>\n",
              "      <td>Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0a4abcb-9d00-44ca-816c-b6dd777fa5d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0a4abcb-9d00-44ca-816c-b6dd777fa5d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0a4abcb-9d00-44ca-816c-b6dd777fa5d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFQpzaIQyFoq"
      },
      "source": [
        "# القسم الثالث - تطبيق النموذج واستخدامه ونتائجه\n",
        "في هذا القسم نحتاج فقط إلى تحميل الكود المطلوب والنماذج من جيت هاب، واستخدام النظام مباشرة"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- تحميل البيانات والمكتبات\n",
        "للمرة الأولى فقط"
      ],
      "metadata": {
        "id": "Q2Oo5capELmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "!wget -O arabic_quran_news_wv_model_300.wv http://arbsq.net/shared/arabic_quran_news_wv_model_300.wv \n",
        "wv_dir=\"wv\"\n",
        "if not os.path.exists(wv_dir): os.mkdir(wv_dir)\n",
        "!mv arabic_quran_news_wv_model_300.wv wv/arabic_quran_news_wv_model_300.wv\n",
        "\n",
        "if os.path.exists(\"code_utils\"): shutil.rmtree(\"code_utils\")\n",
        "!git clone https://github.com/hmghaly/arabicthon.git code_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ6Q2J3DAPTY",
        "outputId": "463c27c4-5aca-4ac6-8ae3-09a9b509f297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-28 01:21:29--  http://arbsq.net/shared/arabic_quran_news_wv_model_300.wv\n",
            "Resolving arbsq.net (arbsq.net)... 107.180.44.147\n",
            "Connecting to arbsq.net (arbsq.net)|107.180.44.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 105418348 (101M)\n",
            "Saving to: ‘arabic_quran_news_wv_model_300.wv’\n",
            "\n",
            "arabic_quran_news_w 100%[===================>] 100.53M  32.0MB/s    in 4.3s    \n",
            "\n",
            "2022-05-28 01:21:33 (23.5 MB/s) - ‘arabic_quran_news_wv_model_300.wv’ saved [105418348/105418348]\n",
            "\n",
            "Cloning into 'code_utils'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 25 (delta 11), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- بدء المكتبات\n",
        "يجب القيام بهذه الخطوة كل مرة لاستخدام النظام"
      ],
      "metadata": {
        "id": "jjL3VJueFmQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from code_utils.arabicthon import *\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "wv_fpath=\"wv/arabic_quran_news_wv_model_300.wv\"\n",
        "arabic_quran_news_model = Word2Vec.load(wv_fpath)\n",
        "\n",
        "frame_model_fpath=\"code_utils/frame_model.model\"\n",
        "checkpoint = torch.load(frame_model_fpath)\n",
        "model_feature_extraction_params=checkpoint[\"feature_extraction_parameters\"]\n",
        "model_feature_extraction_params[\"wv\"]=arabic_quran_news_model\n",
        "frame_labels=checkpoint[\"labels\"]\n",
        "frame_rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "frame_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "frame_rnn.eval()\n",
        "\n",
        "pos_model_fpath=\"code_utils/pos_model.model\"\n",
        "checkpoint = torch.load(pos_model_fpath)\n",
        "pos_model_labels=checkpoint[\"labels\"]\n",
        "pos_rnn = RNN(checkpoint[\"n_input\"] ,checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] ,checkpoint[\"n_layers\"] ,checkpoint[\"matching_in_out\"]).to(device)\n",
        "pos_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "pos_rnn.eval()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLeKT8oIFrDy",
        "outputId": "5963fbd5-9ca5-45ce-de58-3fba6bde88e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (lstm): LSTM(868, 512, num_layers=2)\n",
              "  (hidden2out): Linear(in_features=512, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- استخدام النظام\n",
        "يمكن هنا إدخال أي جملة كي يقوم النظام بتحليلها"
      ],
      "metadata": {
        "id": "E-wN2OJYHKbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence=\"قال أنا عبد الله آتاني الكتاب وجعلني نبيا\"\n",
        "sample_sentence=\"أعطني هذا الكتاب وقال ماذا يفعل هنا\"\n",
        "sentence=input(\"يرجى إدخال جملة لتحليلها\\n\") or sample_sentence\n",
        "output=predict_pos_frame(sentence,pos_rnn,frame_rnn,pos_model_labels,frame_labels,model_feature_extraction_params)\n",
        "df = pd.DataFrame(output,columns =['الكلمات',\"أقسام الكلام\",\"أطر الأفعال\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "3d-bBo2_HTV0",
        "outputId": "cdc6b580-b01d-4a32-9263-ee26bfa706e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "يرجى إدخال جملة لتحليلها\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/arabicthon/code_utils/arabicthon.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  feature_list=torch.tensor(feature_list)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  الكلمات   أقسام الكلام     أطر الأفعال\n",
              "0   أعطني           Verb  V + Prep + Obj\n",
              "1     هذا  Demonstrative                \n",
              "2  الكتاب           Noun                \n",
              "3    وقال           Verb        V + 2OBJ\n",
              "4    ماذا           Noun                \n",
              "5    يفعل           Verb         V + OBJ\n",
              "6     هنا          Other                "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f59cc8ea-285a-43e3-aa89-c00775aa6366\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>الكلمات</th>\n",
              "      <th>أقسام الكلام</th>\n",
              "      <th>أطر الأفعال</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>أعطني</td>\n",
              "      <td>Verb</td>\n",
              "      <td>V + Prep + Obj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>هذا</td>\n",
              "      <td>Demonstrative</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>الكتاب</td>\n",
              "      <td>Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>وقال</td>\n",
              "      <td>Verb</td>\n",
              "      <td>V + 2OBJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ماذا</td>\n",
              "      <td>Noun</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>يفعل</td>\n",
              "      <td>Verb</td>\n",
              "      <td>V + OBJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>هنا</td>\n",
              "      <td>Other</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f59cc8ea-285a-43e3-aa89-c00775aa6366')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f59cc8ea-285a-43e3-aa89-c00775aa6366 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f59cc8ea-285a-43e3-aa89-c00775aa6366');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G2iBjbEcMZzR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "arabicthon.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}